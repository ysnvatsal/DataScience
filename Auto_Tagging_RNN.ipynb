{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysnvatsal/DataScience/blob/main/Auto_Tagging_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtPKZPpFxD6g"
      },
      "source": [
        "# Objective\n",
        "\n",
        "Build a model to automatically predict tags for a given a StackExchange question by using the text of the question.\n",
        "![alt text](https://cdn.sstatic.net/Sites/stackoverflow/company/img/logos/se/se-logo.svg?v=d29f0785ebb7)\n",
        "\n",
        "__Dataset Specs__: Over 85,000 questions\n",
        "\n",
        "[Download Link](https://www.kaggle.com/stackoverflow/statsquestions#Questions.csv)\n",
        "\n",
        "__License__\n",
        "\n",
        "All Stack Exchange user contributions are licensed under [CC-BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/) with [attribution required](http://blog.stackoverflow.com/2009/06/attribution-required/).\n",
        "\n",
        "<br>\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_axH7-PrUFT",
        "outputId": "7fe32c57-d3f9-4786-a55b-3d02fc9a0678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# optional step (if you are working on colab)\n",
        "# mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfaOlnHpy-Va"
      },
      "source": [
        "# Steps to Follow\n",
        "\n",
        "\n",
        "\n",
        "1. Load Data and Import Libraries\n",
        "2. Text Cleaning\n",
        "3. Merge Tags with Questions\n",
        "4. Dataset Preparation\n",
        "5. Text Representation\n",
        "6. Model Building\n",
        "    1. Define Model Architecture\n",
        "    2. Train the Model\n",
        "7. Model Predictions\n",
        "8. Model Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVFrjcv4H_pa"
      },
      "source": [
        "# Load Data and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gitKl0VQbmBN"
      },
      "outputs": [],
      "source": [
        "# for string matching\n",
        "import re\n",
        "\n",
        "# for reading data\n",
        "import pandas as pd\n",
        "\n",
        "# for handling html data\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhQkcqvqMVeK"
      },
      "outputs": [],
      "source": [
        "# extract data from the ZIP file\n",
        "!unzip 'statsquestions.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qLXg0bRfclmw"
      },
      "outputs": [],
      "source": [
        "# load the stackoverflow questions dataset\n",
        "questions_df = pd.read_csv('Questions.csv',encoding='latin-1')\n",
        "\n",
        "# load the tags dataset\n",
        "tags_df = pd.read_csv('Tags.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w-hQccRCMgY"
      },
      "source": [
        "### Data Dictionary\n",
        "\n",
        "1. Id: Question ID\n",
        "2. OwnerUserId: User ID\n",
        "3. CreationDate: Date of posting question\n",
        "4. Score: Count of Upvotes received by the question\n",
        "5. Title: Title of the question\n",
        "6. Body: Text body of the question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "8pxycLMRKvO4",
        "outputId": "8bc33e1d-f8b1-47ee-8ac5-b4b199dc386d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  OwnerUserId          CreationDate  Score  \\\n",
              "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
              "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
              "2  22         66.0  2010-07-19T19:25:39Z    208   \n",
              "3  31         13.0  2010-07-19T19:28:44Z    138   \n",
              "4  36          8.0  2010-07-19T19:31:47Z     58   \n",
              "\n",
              "                                                                Title  \\\n",
              "0                  The Two Cultures: statistics vs. machine learning?   \n",
              "1                                      Forecasting demographic census   \n",
              "2                 Bayesian and frequentist reasoning in plain English   \n",
              "3  What is the meaning of p values and t values in statistical tests?   \n",
              "4          Examples for teaching: Correlation does not mean causation   \n",
              "\n",
              "                                                                                                                                                                                                      Body  \n",
              "0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...  \n",
              "1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...  \n",
              "2                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n  \n",
              "3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....  \n",
              "4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8b1ec45-cf32-490d-8996-87ded044a533\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>OwnerUserId</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>Score</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2010-07-19T19:14:44Z</td>\n",
              "      <td>272</td>\n",
              "      <td>The Two Cultures: statistics vs. machine learning?</td>\n",
              "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>59.0</td>\n",
              "      <td>2010-07-19T19:24:36Z</td>\n",
              "      <td>4</td>\n",
              "      <td>Forecasting demographic census</td>\n",
              "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>66.0</td>\n",
              "      <td>2010-07-19T19:25:39Z</td>\n",
              "      <td>208</td>\n",
              "      <td>Bayesian and frequentist reasoning in plain English</td>\n",
              "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2010-07-19T19:28:44Z</td>\n",
              "      <td>138</td>\n",
              "      <td>What is the meaning of p values and t values in statistical tests?</td>\n",
              "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2010-07-19T19:31:47Z</td>\n",
              "      <td>58</td>\n",
              "      <td>Examples for teaching: Correlation does not mean causation</td>\n",
              "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8b1ec45-cf32-490d-8996-87ded044a533')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8b1ec45-cf32-490d-8996-87ded044a533 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8b1ec45-cf32-490d-8996-87ded044a533');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bcc14cd2-ef07-4e3e-89b8-e77ae206b7d9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bcc14cd2-ef07-4e3e-89b8-e77ae206b7d9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bcc14cd2-ef07-4e3e-89b8-e77ae206b7d9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#print first 5 rows\n",
        "questions_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siBpKFe3IZNw"
      },
      "source": [
        "# Text Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmeuzAF9Ic1d"
      },
      "source": [
        "Let's define a function to clean the text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ADh9l-RWNSDU"
      },
      "outputs": [],
      "source": [
        "def cleaner(text):\n",
        "\n",
        "  # take off html tags\n",
        "  text = BeautifulSoup(text).get_text()\n",
        "\n",
        "  # fetch alphabetic characters\n",
        "  text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "\n",
        "  # convert text to lower case\n",
        "  text = text.lower()\n",
        "\n",
        "  # split text into tokens to remove whitespaces\n",
        "  tokens = text.split()\n",
        "\n",
        "  return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "o98nUFycNSB-"
      },
      "outputs": [],
      "source": [
        "# call preprocessing function\n",
        "questions_df['cleaned_text'] = questions_df['Body'].apply(cleaner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "umvS_4ZQNR6r",
        "outputId": "749e1b51-0a17-411a-f55f-0e2a5e08aa7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?</li>\\n<li>if let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far can i forecast it into the\\nfuture?</li>\\n<li>if some of the census zone change\\nlightly in boundaries, how can i\\naccount for that change?</li>\\n<li>What are the methods to validate\\ncensus forecasts? for example, if i\\nhave data for existing 5 census\\nperiods, should I model the first 3\\nand test it on the latter two? or is\\nthere another way?</li>\\n<li>what's the state of practice in\\nforecasting census data, and what are\\nsome of the state of the art methods?</li>\\n</ul>\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "questions_df['Body'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "FoEZ0aQ7KvN2",
        "outputId": "404029c5-f3f0-4e03-e835-1bca19e62afe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what are some of the ways to forecast demographic census with some validation and calibration techniques some of the concerns census blocks vary in sizes as rural areas are a lot larger than condensed urban areas is there a need to account for the area size difference if let s say i have census data dating back to census periods how far can i forecast it into the future if some of the census zone change lightly in boundaries how can i account for that change what are the methods to validate census forecasts for example if i have data for existing census periods should i model the first and test it on the latter two or is there another way what s the state of practice in forecasting census data and what are some of the state of the art methods'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "questions_df['cleaned_text'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTPISO70LOM4"
      },
      "source": [
        "# Merge Tags with Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTXwGw2xKhWk"
      },
      "source": [
        "Let's now explore the tags data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4p9JAFA9tTxO",
        "outputId": "0a63931c-b10f-4a2f-d425-110762aa92f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id            Tag\n",
              "0   1       bayesian\n",
              "1   1          prior\n",
              "2   1    elicitation\n",
              "3   2  distributions\n",
              "4   2      normality"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9223bb78-760f-4bbc-a9fb-3faec14116ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>bayesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>prior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>elicitation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>distributions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>normality</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9223bb78-760f-4bbc-a9fb-3faec14116ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9223bb78-760f-4bbc-a9fb-3faec14116ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9223bb78-760f-4bbc-a9fb-3faec14116ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3a574990-0516-4472-af02-7611fe51d7c4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a574990-0516-4472-af02-7611fe51d7c4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3a574990-0516-4472-af02-7611fe51d7c4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tags_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVGubRcWe01J",
        "outputId": "27431185-5ebc-4629-cdf4-897c5f68c4b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1315"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# count of unique tags\n",
        "len(tags_df['Tag'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqW5nBknesV-",
        "outputId": "32472af5-c4a7-4143-9c25-193787597c1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "r                       13236\n",
              "regression              10959\n",
              "machine-learning         6089\n",
              "time-series              5559\n",
              "probability              4217\n",
              "                        ...  \n",
              "fmincon                     1\n",
              "doc2vec                     1\n",
              "sympy                       1\n",
              "adversarial-boosting        1\n",
              "corpus-linguistics          1\n",
              "Name: Tag, Length: 1315, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tags_df['Tag'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3SEjB4OwiJ0b"
      },
      "outputs": [],
      "source": [
        "# remove \"-\" from the tags\n",
        "tags_df['Tag']= tags_df['Tag'].apply(lambda x:re.sub(\"-\",\" \",x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MhPvTj6ytcW0",
        "outputId": "2be647bb-3555-457b-aaa3-5560b295faed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id                                       tags\n",
              "0   1             [bayesian, prior, elicitation]\n",
              "1   2                 [distributions, normality]\n",
              "2   3                    [software, open source]\n",
              "3   4  [distributions, statistical significance]\n",
              "4   6                         [machine learning]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ee971e7-4905-4c68-8cb1-64e6ff9c3ed2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[bayesian, prior, elicitation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[distributions, normality]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[software, open source]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[distributions, statistical significance]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>[machine learning]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ee971e7-4905-4c68-8cb1-64e6ff9c3ed2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ee971e7-4905-4c68-8cb1-64e6ff9c3ed2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ee971e7-4905-4c68-8cb1-64e6ff9c3ed2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-16efe590-3dd4-4682-a22d-797abfe6f9e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16efe590-3dd4-4682-a22d-797abfe6f9e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-16efe590-3dd4-4682-a22d-797abfe6f9e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# group tags Id wise\n",
        "tags_df = tags_df.groupby('Id').apply(lambda x:x['Tag'].values).reset_index(name='tags')\n",
        "tags_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "zCnEKm1ouTnm"
      },
      "outputs": [],
      "source": [
        "# merge tags and questions\n",
        "df = pd.merge(questions_df,tags_df,how='inner',on='Id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "fn37BQ5TusSt",
        "outputId": "cad4b768-e014-4732-b75b-96c8d458e23d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  \\\n",
              "0   6   \n",
              "1  21   \n",
              "2  22   \n",
              "3  31   \n",
              "4  36   \n",
              "\n",
              "                                                                                                                                                                                                      Body  \\\n",
              "0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...   \n",
              "1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...   \n",
              "2                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n   \n",
              "3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....   \n",
              "4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...   \n",
              "\n",
              "                                                                                                                                                                                              cleaned_text  \\\n",
              "0  last year i read a blog post from brendan o connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to ...   \n",
              "1  what are some of the ways to forecast demographic census with some validation and calibration techniques some of the concerns census blocks vary in sizes as rural areas are a lot larger than conde...   \n",
              "2                                                                                         how would you describe in plain english the characteristics that distinguish bayesian from frequentist reasoning   \n",
              "3  after taking a statistics course and then trying to help fellow students i noticed one subject that inspires much head desk banging is interpreting the results of statistical hypothesis tests it s...   \n",
              "4  there is an old saying correlation does not mean causation when i teach i tend to use the following standard examples to illustrate this point number of storks and birth rate in denmark number of ...   \n",
              "\n",
              "                                                               tags  \n",
              "0                                                [machine learning]  \n",
              "1                                 [forecasting, population, census]  \n",
              "2                                           [bayesian, frequentist]  \n",
              "3  [hypothesis testing, t test, p value, interpretation, intuition]  \n",
              "4                                           [correlation, teaching]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14029956-a3c6-4087-8dc0-c3331c769e4c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Body</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n",
              "      <td>last year i read a blog post from brendan o connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to ...</td>\n",
              "      <td>[machine learning]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n",
              "      <td>what are some of the ways to forecast demographic census with some validation and calibration techniques some of the concerns census blocks vary in sizes as rural areas are a lot larger than conde...</td>\n",
              "      <td>[forecasting, population, census]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
              "      <td>how would you describe in plain english the characteristics that distinguish bayesian from frequentist reasoning</td>\n",
              "      <td>[bayesian, frequentist]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n",
              "      <td>after taking a statistics course and then trying to help fellow students i noticed one subject that inspires much head desk banging is interpreting the results of statistical hypothesis tests it s...</td>\n",
              "      <td>[hypothesis testing, t test, p value, interpretation, intuition]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n",
              "      <td>there is an old saying correlation does not mean causation when i teach i tend to use the following standard examples to illustrate this point number of storks and birth rate in denmark number of ...</td>\n",
              "      <td>[correlation, teaching]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14029956-a3c6-4087-8dc0-c3331c769e4c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14029956-a3c6-4087-8dc0-c3331c769e4c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14029956-a3c6-4087-8dc0-c3331c769e4c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98a8b9e2-8cd5-4e5a-8c50-f1327b1fcb15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98a8b9e2-8cd5-4e5a-8c50-f1327b1fcb15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98a8b9e2-8cd5-4e5a-8c50-f1327b1fcb15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "df = df[['Id','Body','cleaned_text','tags']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2cqkOjieMKBk",
        "outputId": "553a4a19-4b7b-4c4e-f085-16a4485bb865"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(85085, 4)"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV6KXBw1MRyY"
      },
      "source": [
        "There are over 85,000 unique questions and over 1300 tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_22ook_MiRv"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3uj_0l0jwL3f"
      },
      "outputs": [],
      "source": [
        "# check frequency of occurence of each tag\n",
        "freq= {}\n",
        "for i in df['tags']:\n",
        "  for j in i:\n",
        "    if j in freq.keys():\n",
        "      freq[j] = freq[j] + 1\n",
        "    else:\n",
        "      freq[j] = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YttMdsTKLFeV",
        "outputId": "2e083590-a1f7-4893-f523-9b4c44c20f9b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'machine learning': 6089,\n",
              " 'forecasting': 1422,\n",
              " 'population': 219,\n",
              " 'census': 32,\n",
              " 'bayesian': 2656,\n",
              " 'frequentist': 144,\n",
              " 'hypothesis testing': 3869,\n",
              " 't test': 1418,\n",
              " 'p value': 1040,\n",
              " 'interpretation': 860,\n",
              " 'intuition': 168,\n",
              " 'correlation': 2871,\n",
              " 'teaching': 107,\n",
              " 'nonparametric': 922,\n",
              " 'survival': 1081,\n",
              " 'hazard': 162,\n",
              " 'time series': 5559,\n",
              " 'garch': 302,\n",
              " 'volatility forecasting': 64,\n",
              " 'finance': 200,\n",
              " 'data visualization': 1549,\n",
              " 'references': 1076,\n",
              " 'methodology': 142,\n",
              " 'theory': 137,\n",
              " 'classification': 2881,\n",
              " 'information retrieval': 85,\n",
              " 'text mining': 432,\n",
              " 'communication': 40,\n",
              " 'sample size': 847,\n",
              " 'polling': 19,\n",
              " 'r': 13236,\n",
              " 'poisson': 865,\n",
              " 'count data': 347,\n",
              " 'epidemiology': 198,\n",
              " 'regression': 10959,\n",
              " 'outliers': 629,\n",
              " 'scales': 248,\n",
              " 'ordinal': 624,\n",
              " 'likert': 366,\n",
              " 'interval': 87,\n",
              " 'software': 151,\n",
              " 'standard deviation': 866,\n",
              " 'variance': 1576,\n",
              " 'anova': 2505,\n",
              " 'random effects model': 569,\n",
              " 'modeling': 1055,\n",
              " 'spatial': 429,\n",
              " 'clustering': 1952,\n",
              " 'estimation': 1533,\n",
              " 'beta binomial': 63,\n",
              " 'distributions': 3501,\n",
              " 'data transformation': 1057,\n",
              " 'logarithm': 172,\n",
              " 'regression strategies': 162,\n",
              " 'feature selection': 997,\n",
              " 'self study': 3732,\n",
              " 'econometrics': 989,\n",
              " 'autocorrelation': 678,\n",
              " 'stationarity': 337,\n",
              " 'white noise': 54,\n",
              " 'boosting': 240,\n",
              " 'confidence interval': 1776,\n",
              " 'bootstrap': 814,\n",
              " 'spss': 1296,\n",
              " 'proportion': 503,\n",
              " 'chi squared': 1261,\n",
              " 'binary data': 570,\n",
              " 'group differences': 309,\n",
              " 'neural networks': 1897,\n",
              " 'monitoring': 4,\n",
              " 'probability': 4217,\n",
              " 'stochastic processes': 530,\n",
              " 'hidden markov model': 314,\n",
              " 'interaction': 946,\n",
              " 'power': 312,\n",
              " 'signal processing': 151,\n",
              " 'missing data': 652,\n",
              " 'small sample': 295,\n",
              " 'mean': 842,\n",
              " 'uncertainty': 165,\n",
              " 'cross validation': 1344,\n",
              " 'aic': 431,\n",
              " 'fitting': 357,\n",
              " 'iid': 61,\n",
              " 'normal distribution': 2181,\n",
              " 'mathematical statistics': 1888,\n",
              " 'sampling': 1363,\n",
              " 'skewness': 325,\n",
              " 'likelihood ratio': 238,\n",
              " 'large data': 266,\n",
              " 'covariance': 666,\n",
              " 'mixed model': 1998,\n",
              " 'generalized linear model': 1614,\n",
              " 'gam': 199,\n",
              " 'error message': 31,\n",
              " 'inference': 625,\n",
              " 'kalman filter': 180,\n",
              " 'multiple comparisons': 825,\n",
              " 'nonlinear regression': 514,\n",
              " 'nls': 50,\n",
              " 'science': 9,\n",
              " 'svm': 1283,\n",
              " 'stata': 842,\n",
              " '2sls': 66,\n",
              " 'mann whitney u test': 242,\n",
              " 'humor': 2,\n",
              " 'categorical data': 1703,\n",
              " 'independence': 480,\n",
              " 'log linear': 79,\n",
              " 'permutation test': 8,\n",
              " 'normalization': 484,\n",
              " 'assumptions': 418,\n",
              " 'parametric': 155,\n",
              " 'pooling': 92,\n",
              " 'model selection': 876,\n",
              " 'lmer': 463,\n",
              " 'mathematics': 88,\n",
              " 'heteroscedasticity': 483,\n",
              " 'pearson': 258,\n",
              " 'intraclass correlation': 135,\n",
              " 'pivot': 17,\n",
              " 'dataset': 840,\n",
              " 'data mining': 950,\n",
              " 'trend': 256,\n",
              " 'learning': 108,\n",
              " 'birthday paradox': 13,\n",
              " 'average': 277,\n",
              " 'sas': 496,\n",
              " 'simulation': 676,\n",
              " 'power analysis': 365,\n",
              " 'descriptive statistics': 430,\n",
              " 'z statistic': 40,\n",
              " 'lm': 153,\n",
              " 'regression coefficients': 643,\n",
              " 'experiment design': 780,\n",
              " 'careers': 31,\n",
              " 'logistic': 3316,\n",
              " 'multiple regression': 2054,\n",
              " 'binomial': 935,\n",
              " 'kruskal wallis': 170,\n",
              " 'repeated measures': 1335,\n",
              " 'crossover study': 31,\n",
              " 'histogram': 260,\n",
              " 'loss functions': 176,\n",
              " 'fourier transform': 90,\n",
              " 'markov process': 445,\n",
              " 'glmnet': 202,\n",
              " 'arima': 917,\n",
              " 'confirmatory factor': 157,\n",
              " 'instrumental variables': 227,\n",
              " 'median': 273,\n",
              " 'standard error': 629,\n",
              " 'odds ratio': 275,\n",
              " 'summary statistics': 338,\n",
              " 'resampling': 171,\n",
              " 'statistical significance': 2666,\n",
              " 'life expectancy': 9,\n",
              " 'prediction': 832,\n",
              " 'cox model': 510,\n",
              " 'kaplan meier': 97,\n",
              " 'copula': 155,\n",
              " 't distribution': 172,\n",
              " 'fixed effects model': 391,\n",
              " 'hausman': 60,\n",
              " 'unbalanced classes': 247,\n",
              " 'jags': 201,\n",
              " 'parallel computing': 30,\n",
              " 'seasonality': 270,\n",
              " 'index decomposition': 15,\n",
              " 'kolmogorov smirnov': 266,\n",
              " 'lognormal': 275,\n",
              " 'power law': 89,\n",
              " 'qq plot': 127,\n",
              " 'matlab': 941,\n",
              " 'cart': 593,\n",
              " 'difference in difference': 133,\n",
              " 'nonlinear': 191,\n",
              " 'unsupervised learning': 232,\n",
              " 'predictive models': 1189,\n",
              " 'pca': 1395,\n",
              " 'pls': 109,\n",
              " 'distance': 304,\n",
              " 'k nearest neighbour': 236,\n",
              " 'discriminant analysis': 234,\n",
              " 'ancova': 300,\n",
              " 'scikit learn': 440,\n",
              " 'validation': 296,\n",
              " 'performance': 153,\n",
              " 'out of sample': 74,\n",
              " 'computational statistics': 348,\n",
              " 'lsa': 49,\n",
              " 'bic': 139,\n",
              " 'probit': 226,\n",
              " 'lags': 120,\n",
              " 'normality': 371,\n",
              " 'open source': 12,\n",
              " 'propensity scores': 148,\n",
              " 'multiple imputation': 223,\n",
              " 'random variable': 745,\n",
              " 'least squares': 898,\n",
              " 'non independent': 259,\n",
              " 'central limit theorem': 236,\n",
              " 'bias': 396,\n",
              " 'negative binomial': 358,\n",
              " 'glmm': 359,\n",
              " 'expectation maximization': 270,\n",
              " 'auc': 172,\n",
              " 'cluster sample': 68,\n",
              " 'multivariate analysis': 1116,\n",
              " 'continuous data': 317,\n",
              " 'r squared': 372,\n",
              " 'mae': 10,\n",
              " 'reliability': 314,\n",
              " 'psychometrics': 228,\n",
              " 'validity': 71,\n",
              " 'error propagation': 131,\n",
              " 'functional data analysis': 38,\n",
              " 'python': 955,\n",
              " 'mutual information': 150,\n",
              " 'multivariable': 45,\n",
              " 'history': 74,\n",
              " 'monte carlo': 504,\n",
              " 'poisson process': 119,\n",
              " 'non stationary': 144,\n",
              " 'piecewise linear': 30,\n",
              " 'finite population': 49,\n",
              " 'mcmc': 635,\n",
              " 'bugs': 102,\n",
              " 'likelihood': 407,\n",
              " 'circular statistics': 68,\n",
              " 'multilevel analysis': 663,\n",
              " 'aggregation': 128,\n",
              " 'goodness of fit': 567,\n",
              " 'roc': 358,\n",
              " 'random generation': 345,\n",
              " 'sensitivity analysis': 48,\n",
              " 'quasi monte carlo': 11,\n",
              " 'fisher': 65,\n",
              " 'centering': 73,\n",
              " 'conjugate prior': 106,\n",
              " 'estimators': 205,\n",
              " 'psychology': 87,\n",
              " 'random forest': 935,\n",
              " 'euclidean': 60,\n",
              " 'prior': 340,\n",
              " 'gamma distribution': 319,\n",
              " 'inverse gamma': 29,\n",
              " 'arma': 255,\n",
              " 'lme': 183,\n",
              " 'panel data': 966,\n",
              " 'residuals': 582,\n",
              " 'libsvm': 177,\n",
              " 'error': 481,\n",
              " 'importance': 80,\n",
              " 'uniform': 268,\n",
              " 'partial correlation': 84,\n",
              " 'ecology': 109,\n",
              " 'spatio temporal': 55,\n",
              " 'scatterplot': 131,\n",
              " 'linear model': 937,\n",
              " 'control': 73,\n",
              " 'maximum likelihood': 1209,\n",
              " 'optimization': 898,\n",
              " 'endogeneity': 118,\n",
              " 'heckman': 28,\n",
              " 'autoregressive': 307,\n",
              " 'dynamic regression': 63,\n",
              " 'networks': 112,\n",
              " 'subset': 56,\n",
              " 'igraph': 30,\n",
              " 'coefficient': 99,\n",
              " 'covariance matrix': 332,\n",
              " 'reinforcement learning': 145,\n",
              " 'q learning': 12,\n",
              " 'state space models': 119,\n",
              " 'meta analysis': 480,\n",
              " 'heterogeneity': 32,\n",
              " 'expected value': 645,\n",
              " 'conditional expectation': 245,\n",
              " 'martingale': 20,\n",
              " 'diagnostic': 145,\n",
              " 'geometric distribution': 47,\n",
              " 'marketing': 60,\n",
              " 'moderation': 61,\n",
              " 'information theory': 212,\n",
              " 'survey': 617,\n",
              " 'model': 567,\n",
              " 'regularization': 317,\n",
              " 'high dimensional': 97,\n",
              " 'nonparametric regression': 19,\n",
              " 'time complexity': 23,\n",
              " 'bayesian network': 192,\n",
              " 'bayesian score': 5,\n",
              " 'generalized moments': 77,\n",
              " 'time varying covariate': 92,\n",
              " 'dlm': 38,\n",
              " 'k means': 465,\n",
              " 'multicollinearity': 438,\n",
              " 'matrix': 413,\n",
              " 'ridge regression': 228,\n",
              " 'csv file': 9,\n",
              " 'prediction interval': 185,\n",
              " 'tolerance interval': 26,\n",
              " 'cdf': 250,\n",
              " 'order statistics': 165,\n",
              " 'transform': 14,\n",
              " 'bernoulli distribution': 179,\n",
              " 'mode': 71,\n",
              " 'quantiles': 293,\n",
              " 'penalized': 50,\n",
              " 'algorithms': 500,\n",
              " 'factor analysis': 642,\n",
              " 'correspondence analysis': 61,\n",
              " 'traminer': 57,\n",
              " 'integral': 90,\n",
              " 'threshold': 96,\n",
              " 'kernel trick': 321,\n",
              " 'polynomial': 154,\n",
              " 'terminology': 551,\n",
              " 'gee': 177,\n",
              " 'eviews': 47,\n",
              " 'elicitation': 8,\n",
              " 'contingency tables': 253,\n",
              " 'matrix decomposition': 123,\n",
              " 'tukey hsd': 87,\n",
              " 'accuracy': 231,\n",
              " 'data imputation': 238,\n",
              " 'change point': 125,\n",
              " 'sufficient statistics': 106,\n",
              " 'anomaly detection': 61,\n",
              " 'boxplot': 109,\n",
              " 'censoring': 172,\n",
              " 'dimensionality reduction': 407,\n",
              " 'randomized': 8,\n",
              " 'svd': 182,\n",
              " 'predictor': 215,\n",
              " 'pdf': 654,\n",
              " 'nonparametric density': 12,\n",
              " 'density estimation': 46,\n",
              " 'treatment effect': 105,\n",
              " 'post hoc': 284,\n",
              " 'bonferroni': 148,\n",
              " 'posterior': 291,\n",
              " 'metropolis hastings': 138,\n",
              " 'gis': 15,\n",
              " 'sample': 450,\n",
              " 'paired comparisons': 232,\n",
              " 'combining p values': 45,\n",
              " 'convergence': 370,\n",
              " 'causality': 300,\n",
              " 'matching': 147,\n",
              " 'confounding': 106,\n",
              " 'permutation': 231,\n",
              " '2d': 1,\n",
              " 'unbiased estimator': 245,\n",
              " 'wilcoxon': 266,\n",
              " 'decision theory': 121,\n",
              " 'rms': 93,\n",
              " 'method of moments': 61,\n",
              " 'numpy': 31,\n",
              " 'gbm': 138,\n",
              " 'symmetry': 20,\n",
              " 'gradient descent': 277,\n",
              " 'backpropagation': 120,\n",
              " 'java': 75,\n",
              " 'softmax': 31,\n",
              " 'online': 100,\n",
              " 'sequential analysis': 67,\n",
              " 'exponential': 295,\n",
              " 'excel': 257,\n",
              " 'similarities': 225,\n",
              " 'percentage': 119,\n",
              " 'conditional probability': 837,\n",
              " 'exponential family': 115,\n",
              " 'weighted mean': 116,\n",
              " 'effect size': 375,\n",
              " 'lasso': 490,\n",
              " 'asymptotics': 236,\n",
              " 'definition': 156,\n",
              " 'neyman pearson lemma': 28,\n",
              " 'ensemble': 159,\n",
              " 'stacking': 27,\n",
              " 'moment': 8,\n",
              " 'measurement': 177,\n",
              " 'multinomial': 480,\n",
              " 'nominal': 86,\n",
              " 'bayes': 273,\n",
              " 'joint distribution': 253,\n",
              " 'association measure': 74,\n",
              " 'statistical': 51,\n",
              " 'distance functions': 222,\n",
              " 'recommender system': 206,\n",
              " 'mediation': 162,\n",
              " 'mcnemar test': 67,\n",
              " 'data generating process': 14,\n",
              " 'robust': 282,\n",
              " 'kullback leibler': 137,\n",
              " 'basic concepts': 226,\n",
              " 'genetics': 141,\n",
              " 'entropy': 259,\n",
              " 'truncation': 81,\n",
              " 'pattern recognition': 253,\n",
              " 'linear': 256,\n",
              " 'covariate': 104,\n",
              " 'ratio': 117,\n",
              " 'latent variable': 177,\n",
              " 'sensitivity': 76,\n",
              " 'specificity': 48,\n",
              " 'point estimation': 76,\n",
              " 'model based clustering': 45,\n",
              " 'signed rank test': 34,\n",
              " 'canonical correlation': 56,\n",
              " 'information': 24,\n",
              " 'zero inflation': 174,\n",
              " 'logarithmic series': 4,\n",
              " 'gaussian mixture': 261,\n",
              " 'dice': 84,\n",
              " 'lme4': 371,\n",
              " 'numerics': 50,\n",
              " 'weighted regression': 150,\n",
              " 'noise': 60,\n",
              " 'poisson binomial': 26,\n",
              " 'multi class': 148,\n",
              " 'oversampling': 30,\n",
              " 'bimodal': 22,\n",
              " 'z test': 116,\n",
              " 'naive bayes': 318,\n",
              " 'smoothing': 191,\n",
              " 'games': 98,\n",
              " 'nested': 183,\n",
              " 'non nested': 17,\n",
              " 'skew normal': 22,\n",
              " 'mse': 128,\n",
              " 'beta regression': 59,\n",
              " 'barplot': 40,\n",
              " 'eda': 116,\n",
              " 'ab test': 107,\n",
              " 'empirical': 79,\n",
              " 'confidence': 115,\n",
              " 'vowpal wabbit': 9,\n",
              " 'quadratic form': 74,\n",
              " 'disease': 10,\n",
              " 'arch': 41,\n",
              " 'semiparametric': 13,\n",
              " 'ranking': 338,\n",
              " 'mice': 62,\n",
              " 'rpart': 92,\n",
              " 'nlme': 114,\n",
              " 'overdispersion': 90,\n",
              " 'database': 18,\n",
              " 'caret': 233,\n",
              " 'correlation matrix': 23,\n",
              " 'cohens d': 75,\n",
              " 'geostatistics': 58,\n",
              " 'statistical bias': 12,\n",
              " 'clustered standard errors': 73,\n",
              " 'education': 48,\n",
              " 'graphical model': 231,\n",
              " 'graph theory': 160,\n",
              " 'conditional random field': 26,\n",
              " 'markov random field': 12,\n",
              " 'logit': 374,\n",
              " 'natural language': 335,\n",
              " 'word embeddings': 44,\n",
              " 'language models': 19,\n",
              " 'deep learning': 600,\n",
              " 'parameter optimization': 78,\n",
              " 'fishers exact': 180,\n",
              " 'rejection sampling': 43,\n",
              " 'concavity': 2,\n",
              " 'hierarchical bayesian': 237,\n",
              " 'importance sampling': 51,\n",
              " 'particle filter': 49,\n",
              " 'data preprocessing': 78,\n",
              " 'manova': 252,\n",
              " 'uninformative prior': 35,\n",
              " 'tables': 39,\n",
              " 'sparse': 123,\n",
              " 'random walk': 74,\n",
              " 'coding': 25,\n",
              " 'cauchy': 35,\n",
              " 'dendrogram': 32,\n",
              " 'c#': 20,\n",
              " 'var': 289,\n",
              " 'granger causality': 98,\n",
              " 'impulse response': 39,\n",
              " 'logrank': 37,\n",
              " 'deming regression': 20,\n",
              " 'total least squares': 25,\n",
              " 'case control study': 68,\n",
              " 'standardization': 300,\n",
              " 'big data': 24,\n",
              " 'calibration': 87,\n",
              " 'image processing': 227,\n",
              " 'parameterization': 126,\n",
              " 'matplotlib': 19,\n",
              " 'probabilistic programming': 23,\n",
              " 'belief propagation': 9,\n",
              " 'interpolation': 130,\n",
              " 'splines': 173,\n",
              " 'proportional hazards': 16,\n",
              " 'cointegration': 268,\n",
              " 'ecm': 23,\n",
              " 'residual analysis': 89,\n",
              " 'puzzle': 9,\n",
              " 'laplace distribution': 29,\n",
              " 'inter rater': 134,\n",
              " 'hyperparameter': 109,\n",
              " 'contrasts': 176,\n",
              " 'demography': 39,\n",
              " 'rule of thumb': 31,\n",
              " 'mixture': 244,\n",
              " 'pivot table': 7,\n",
              " 'self organizing maps': 50,\n",
              " 'f test': 162,\n",
              " 'curve fitting': 288,\n",
              " 'bivariate': 122,\n",
              " 'musical data analysis': 6,\n",
              " 'metric': 132,\n",
              " 'weighted sampling': 98,\n",
              " 'sem': 405,\n",
              " 'weka': 162,\n",
              " 'partitioning': 81,\n",
              " 'multivariate regression': 131,\n",
              " 'rocr': 9,\n",
              " 'mgcv': 64,\n",
              " 'statistical learning': 114,\n",
              " 'partial': 24,\n",
              " 'approximation': 187,\n",
              " 'real time': 31,\n",
              " 'profile likelihood': 25,\n",
              " 'non response': 26,\n",
              " 'beta distribution': 198,\n",
              " 'repeatability': 23,\n",
              " 'scale construction': 9,\n",
              " 'consistency': 106,\n",
              " 'lme4 nlme': 84,\n",
              " 'supervised learning': 191,\n",
              " 'conv neural network': 264,\n",
              " 'theano': 25,\n",
              " 'poisson regression': 233,\n",
              " 'transition matrix': 28,\n",
              " 'quantile regression': 130,\n",
              " 'sums of squares': 109,\n",
              " 'scipy': 90,\n",
              " 'topic models': 123,\n",
              " 'leverage': 23,\n",
              " 'inequality': 15,\n",
              " 'reporting': 128,\n",
              " 'spectral analysis': 75,\n",
              " 'pareto distribution': 70,\n",
              " 'linear algebra': 193,\n",
              " 'kernel smoothing': 284,\n",
              " 'precision recall': 178,\n",
              " 'semi supervised': 40,\n",
              " 'compression': 19,\n",
              " 'lsmeans': 47,\n",
              " 'f statistic': 31,\n",
              " 'variational bayes': 57,\n",
              " 'statsmodels': 52,\n",
              " 'bland altman plot': 14,\n",
              " 'multiarmed bandit': 42,\n",
              " 'stratification': 109,\n",
              " 'hierarchical clustering': 128,\n",
              " 'train': 126,\n",
              " 'analysis': 138,\n",
              " 'markov chain': 111,\n",
              " 'paired data': 134,\n",
              " 'derived distributions': 5,\n",
              " 'valuation': 33,\n",
              " 'concordance': 24,\n",
              " 'optimal stopping': 20,\n",
              " 'method comparison': 69,\n",
              " 'fat tails': 37,\n",
              " 'regression testing': 5,\n",
              " 'frequency': 174,\n",
              " 'spearman rho': 92,\n",
              " 'vecm': 92,\n",
              " 'vif': 58,\n",
              " 'clinical trials': 110,\n",
              " 'causalimpact': 21,\n",
              " 'discrete data': 266,\n",
              " 'library': 12,\n",
              " 'protovis': 1,\n",
              " 'weighted data': 81,\n",
              " 'survey weights': 37,\n",
              " 'pspp': 1,\n",
              " 'dirichlet distribution': 140,\n",
              " 'umvue': 37,\n",
              " 'minimum': 60,\n",
              " 'hypergeometric': 92,\n",
              " 'quasi likelihood': 28,\n",
              " 'stochastic approximation': 14,\n",
              " 'maximum': 91,\n",
              " 'code': 42,\n",
              " 'spearman': 116,\n",
              " 'rank correlation': 87,\n",
              " 'proof': 198,\n",
              " 'segmentation': 68,\n",
              " 'jaccard similarity': 29,\n",
              " 'ranks': 64,\n",
              " 'sentiment analysis': 38,\n",
              " 'minitab': 46,\n",
              " 'programming': 45,\n",
              " 'moving average': 92,\n",
              " 'association rules': 77,\n",
              " 'marginal': 153,\n",
              " 'underdispersion': 16,\n",
              " 'optimal': 10,\n",
              " 'autoencoders': 110,\n",
              " 'tensorflow': 57,\n",
              " 'optimal scaling': 27,\n",
              " 'sample mean': 94,\n",
              " 'search theory': 11,\n",
              " 'exponential smoothing': 121,\n",
              " 'cross correlation': 185,\n",
              " 'measurement error': 243,\n",
              " 'measure theory': 40,\n",
              " 'deviance': 88,\n",
              " 'combining estimates': 4,\n",
              " 'combinatorics': 155,\n",
              " 'deep belief networks': 72,\n",
              " 'computer vision': 102,\n",
              " 'quality control': 81,\n",
              " 'generalized least squares': 110,\n",
              " 'model comparison': 193,\n",
              " 'pymc': 141,\n",
              " 'moments': 198,\n",
              " 'subsampling': 23,\n",
              " 'glmer': 156,\n",
              " 'winbugs': 70,\n",
              " 'lstm': 94,\n",
              " 'sequence analysis': 74,\n",
              " 'rnn': 77,\n",
              " 'funnel plot': 23,\n",
              " 'publication bias': 20,\n",
              " 'elections': 14,\n",
              " 'delta method': 62,\n",
              " 'algebraic statistics': 3,\n",
              " 'function': 79,\n",
              " 'multilabel': 55,\n",
              " 'variability': 51,\n",
              " 'law of large numbers': 35,\n",
              " 'rbf network': 15,\n",
              " 'lavaan': 41,\n",
              " 'range': 30,\n",
              " 'discriminant': 28,\n",
              " 'approximate inference': 9,\n",
              " 'multivariate normal': 127,\n",
              " 'bioinformatics': 123,\n",
              " 'kurtosis': 120,\n",
              " 'car': 9,\n",
              " 'extreme value': 111,\n",
              " 'scoring': 67,\n",
              " 'macroeconomics': 43,\n",
              " 'vc dimension': 27,\n",
              " 'generative models': 39,\n",
              " 'treatment': 7,\n",
              " 'composite': 53,\n",
              " 'model averaging': 28,\n",
              " 'gibbs': 215,\n",
              " 'social network': 77,\n",
              " 'change scores': 42,\n",
              " 'overfitting': 217,\n",
              " 'auxiliary variable': 3,\n",
              " 'growth model': 57,\n",
              " 'augmented dickey fuller': 94,\n",
              " 'multidimensional scaling': 130,\n",
              " 'data association': 17,\n",
              " 'equivalence': 61,\n",
              " 'offset': 56,\n",
              " 'efficiency': 60,\n",
              " 'identifiability': 59,\n",
              " 'finite mixture model': 21,\n",
              " 'collaborative': 14,\n",
              " 'probability inequalities': 114,\n",
              " 'correlated predictors': 26,\n",
              " 'perceptron': 52,\n",
              " 'julia': 8,\n",
              " 'ggplot2': 105,\n",
              " 'risk': 75,\n",
              " 'heuristic': 15,\n",
              " 'notation': 196,\n",
              " 'e1071': 29,\n",
              " 'wishart': 48,\n",
              " 'gamm4': 15,\n",
              " 'queueing': 54,\n",
              " 'degrees of freedom': 205,\n",
              " 'geometry': 44,\n",
              " 'eigenvalues': 136,\n",
              " 'philosophical': 53,\n",
              " 'information geometry': 11,\n",
              " 'lars': 34,\n",
              " 'link function': 73,\n",
              " 'biostatistics': 306,\n",
              " 'artificial intelligence': 72,\n",
              " 'cross section': 85,\n",
              " 'odds': 75,\n",
              " 'mlogit': 37,\n",
              " 'effects': 29,\n",
              " 'type ii errors': 46,\n",
              " 'mixed distribution': 6,\n",
              " 'nnet': 26,\n",
              " 'transportation': 4,\n",
              " 'engineering statistics': 5,\n",
              " 'nonlinearity': 13,\n",
              " 'unit root': 172,\n",
              " 'bounds': 92,\n",
              " 'computing': 29,\n",
              " 'amos': 49,\n",
              " 'invariance': 12,\n",
              " 'frailty': 28,\n",
              " 'weibull': 128,\n",
              " 'observational study': 70,\n",
              " 'design based inference': 4,\n",
              " 'sphericity': 28,\n",
              " 'imbalanced': 42,\n",
              " 'breusch pagan': 13,\n",
              " 'bias correction': 34,\n",
              " 'lrt': 15,\n",
              " 'arithmetic': 45,\n",
              " 'bagging': 76,\n",
              " 'intercept': 86,\n",
              " 'adjustment': 55,\n",
              " 'fuzzy': 47,\n",
              " 'operations research': 18,\n",
              " 'latent class': 56,\n",
              " 'apriori': 26,\n",
              " 'kappa': 81,\n",
              " 'discussion': 13,\n",
              " 'summations': 40,\n",
              " 'homogeneity': 14,\n",
              " 'absolute risk': 8,\n",
              " 'variance decomposition': 18,\n",
              " 'f distribution': 39,\n",
              " 'compositional data': 22,\n",
              " 'non central': 21,\n",
              " 'lorenz curve': 6,\n",
              " 'matrix calculus': 15,\n",
              " 'jacobian': 13,\n",
              " 'adaboost': 30,\n",
              " 'multicore': 3,\n",
              " 'discrete time': 10,\n",
              " 'cfa': 17,\n",
              " 'familywise error': 20,\n",
              " 'twin': 10,\n",
              " 'social science': 27,\n",
              " 'politics': 10,\n",
              " 'scores': 91,\n",
              " 'item analysis': 8,\n",
              " 'gaussian process': 310,\n",
              " 'brownian': 42,\n",
              " 'phylogeny': 18,\n",
              " 'dirichlet process': 72,\n",
              " 'curves': 38,\n",
              " 'score function': 8,\n",
              " 'inferential statistics': 63,\n",
              " 'randomization': 119,\n",
              " 'voting system': 5,\n",
              " 'suppressor': 14,\n",
              " 'tobit regression': 65,\n",
              " 'convex': 23,\n",
              " 'blue': 10,\n",
              " 'signal detection': 58,\n",
              " 'package': 37,\n",
              " 'friedman test': 37,\n",
              " 'chemometrics': 28,\n",
              " 'qsar': 1,\n",
              " 'maximum entropy': 73,\n",
              " 'forecastability': 4,\n",
              " 'convolution': 112,\n",
              " 'ordered logit': 60,\n",
              " 'hierarchical': 132,\n",
              " 'plm': 37,\n",
              " 'geomarketing': 2,\n",
              " 'benchmark': 13,\n",
              " 'conferences': 4,\n",
              " 'dunn test': 23,\n",
              " 'weights': 50,\n",
              " 'dataframe': 30,\n",
              " 'wavelet': 37,\n",
              " 'robust standard error': 46,\n",
              " 'binning': 88,\n",
              " 'word2vec': 50,\n",
              " 'credible interval': 54,\n",
              " 'likelihood ratio test': 6,\n",
              " 'randomness': 99,\n",
              " 'genetic algorithms': 82,\n",
              " 'false discovery rate': 113,\n",
              " 'structural change': 59,\n",
              " 'reproducible research': 38,\n",
              " 'rating': 62,\n",
              " 'poker': 9,\n",
              " 'synthetic data': 21,\n",
              " 'elastic net': 97,\n",
              " 'paradox': 21,\n",
              " 'replication': 44,\n",
              " 'stepwise regression': 139,\n",
              " 'loess': 65,\n",
              " 'coverage probability': 19,\n",
              " 'mplus': 31,\n",
              " 'z score': 84,\n",
              " 'sgd': 14,\n",
              " 'rbm': 74,\n",
              " 'netflix prize': 1,\n",
              " 'latex': 11,\n",
              " 'sweave': 9,\n",
              " 'abc': 19,\n",
              " 'yates correction': 10,\n",
              " 'recursive model': 14,\n",
              " 'mgf': 51,\n",
              " 'journals': 12,\n",
              " 'kendall tau': 67,\n",
              " 'intervention analysis': 67,\n",
              " 'split plot': 44,\n",
              " 'numerical integration': 60,\n",
              " 'polychoric': 4,\n",
              " 'tf idf': 8,\n",
              " 'unit information prior': 3,\n",
              " 'astronomy': 6,\n",
              " 'c++': 38,\n",
              " 'enrichment': 7,\n",
              " 'mathematica': 34,\n",
              " 'feature construction': 206,\n",
              " 'gini': 44,\n",
              " 'interquartile': 14,\n",
              " 'irt': 124,\n",
              " 'rare events': 72,\n",
              " 'point process': 70,\n",
              " 'dependence': 15,\n",
              " 'discontinuity': 33,\n",
              " 'parallel analysis': 8,\n",
              " 'partial plot': 11,\n",
              " 'jeffreys prior': 23,\n",
              " 'clogit': 42,\n",
              " 'kde': 23,\n",
              " 'climate': 15,\n",
              " 'knowledge discovery': 8,\n",
              " 'model evaluation': 86,\n",
              " 'test for trend': 30,\n",
              " 'smallareaestimation': 4,\n",
              " 'bradley terry model': 10,\n",
              " 'competing risks': 19,\n",
              " 'interaction variable': 25,\n",
              " 'singular': 19,\n",
              " 'type i errors': 90,\n",
              " 'jackknife': 24,\n",
              " 'two way': 31,\n",
              " 'k medoids': 27,\n",
              " 'data cleaning': 40,\n",
              " 'conjoint analysis': 42,\n",
              " 'dropout': 24,\n",
              " 'moving window': 27,\n",
              " 'levenes test': 48,\n",
              " 'simpsons paradox': 20,\n",
              " 'presentation': 22,\n",
              " 'random matrix': 30,\n",
              " 'interarrival time': 20,\n",
              " 'rapidminer': 24,\n",
              " 'relative risk': 61,\n",
              " 'coefficient of variation': 57,\n",
              " 'confusion matrix': 71,\n",
              " 'control chart': 25,\n",
              " 'directional statistics': 17,\n",
              " 'application': 41,\n",
              " 'scoring rules': 18,\n",
              " 'factor rotation': 31,\n",
              " 'spatial interaction model': 8,\n",
              " 'truncated normal': 25,\n",
              " 'contrast': 10,\n",
              " 'hotelling t2': 5,\n",
              " 'sql': 23,\n",
              " 'biplot': 32,\n",
              " 'batch normalization': 7,\n",
              " 'multivariate distribution': 20,\n",
              " 'forward backward': 4,\n",
              " 'saddlepoint approximation': 7,\n",
              " 'meta regression': 71,\n",
              " 'dplyr': 3,\n",
              " 'gumbel': 23,\n",
              " 'formula': 34,\n",
              " 'projection': 33,\n",
              " 'regression to the mean': 11,\n",
              " 'hessian': 18,\n",
              " 'nonparametric bayes': 49,\n",
              " 'agreement statistics': 46,\n",
              " 'business intelligence': 29,\n",
              " 'ergodic': 21,\n",
              " 'bernoulli process': 19,\n",
              " 'overlapping data': 17,\n",
              " 'incidence rate ratio': 29,\n",
              " 'open bugs': 16,\n",
              " 'bayes factors': 29,\n",
              " 'ordered probit': 9,\n",
              " 'univariate': 42,\n",
              " 'bnlearn': 1,\n",
              " 'manifold learning': 16,\n",
              " 'units': 24,\n",
              " 'fraud': 19,\n",
              " 'mars': 11,\n",
              " 'extrapolation': 15,\n",
              " 'multiple seasonalities': 33,\n",
              " 'gamlss': 12,\n",
              " 'latent semantic indexing': 13,\n",
              " 'isotonic': 6,\n",
              " 'back transformation': 38,\n",
              " 'hauck donner effect': 33,\n",
              " 'zero inflated': 21,\n",
              " 'baum welch': 10,\n",
              " 'starting values': 9,\n",
              " 'expectation': 10,\n",
              " 'automatic algorithms': 11,\n",
              " 'box jenkins': 19,\n",
              " 'kriging': 35,\n",
              " 'shrinkage': 68,\n",
              " 'steins phenomenon': 17,\n",
              " 'stan': 63,\n",
              " 'differences': 18,\n",
              " 'microarray': 44,\n",
              " 'statistical control': 28,\n",
              " 'fisher information': 94,\n",
              " 'constrained regression': 43,\n",
              " 'recurrent events': 17,\n",
              " 'cooccurrence': 3,\n",
              " 'rasch': 15,\n",
              " 'matrix inverse': 76,\n",
              " 'sign test': 17,\n",
              " 'heatmap': 17,\n",
              " 'disaggregation': 4,\n",
              " 'shape': 8,\n",
              " 'cholesky': 32,\n",
              " 'taylor series': 20,\n",
              " 'hotelling': 20,\n",
              " 'failure': 20,\n",
              " 'derivative': 58,\n",
              " 'geography': 14,\n",
              " 'dag': 15,\n",
              " 'mixed design': 42,\n",
              " 'bayesian anova': 1,\n",
              " 'd prime': 4,\n",
              " 'gradient': 48,\n",
              " 'neuroscience': 22,\n",
              " 'pandas': 22,\n",
              " 'ruby': 8,\n",
              " 'fuzzy set': 16,\n",
              " 'constraint': 28,\n",
              " 'phd': 6,\n",
              " 'non inferiority': 7,\n",
              " 'variance stabilizing': 9,\n",
              " 'scale invariance': 28,\n",
              " 'dispersion': 30,\n",
              " 'blocking': 44,\n",
              " 'radial basis': 32,\n",
              " 'indicator variables': 27,\n",
              " 'filter': 74,\n",
              " 'l moments': 11,\n",
              " 'characteristic function': 23,\n",
              " 'average precision': 20,\n",
              " 'slutsky theorem': 3,\n",
              " 'ellipse': 6,\n",
              " 'nnmf': 19,\n",
              " 'scale estimator': 9,\n",
              " 'decomposition': 19,\n",
              " 'marginal effect': 35,\n",
              " 'variogram': 52,\n",
              " 'fractal': 15,\n",
              " 'nltk': 11,\n",
              " 'explanatory models': 8,\n",
              " 'scalability': 9,\n",
              " 'capture mark recapture': 21,\n",
              " 'splus': 4,\n",
              " 'probability generating fn': 7,\n",
              " 'path model': 46,\n",
              " 'exact test': 15,\n",
              " 'order': 12,\n",
              " 'multinomial logit': 8,\n",
              " 'plyr': 2,\n",
              " 'cronbachs alpha': 55,\n",
              " 'xgboost': 19,\n",
              " 'anderson darling': 31,\n",
              " 'fractional factorial': 37,\n",
              " 'events': 21,\n",
              " 'inliers': 1,\n",
              " 'restrictions': 6,\n",
              " 'interval censoring': 32,\n",
              " 'cost maximization': 20,\n",
              " 'vector fields': 11,\n",
              " 'planned comparisons test': 17,\n",
              " 'infinite variance': 3,\n",
              " 'log likelihood': 43,\n",
              " 'auxiliary particle filter': 1,\n",
              " 'spark mllib': 26,\n",
              " 'condition number': 10,\n",
              " 'missing value': 6,\n",
              " 'ecdf': 31,\n",
              " 'gui': 4,\n",
              " 'modularity': 10,\n",
              " 'irls': 10,\n",
              " 'jmp': 41,\n",
              " 'inverse gaussian distrib': 12,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUDiameNNhPh"
      },
      "source": [
        "Let's find out the most frequent tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WOzWyGfLzli9"
      },
      "outputs": [],
      "source": [
        "# sort the dictionary in descending order\n",
        "freq = dict(sorted(freq.items(), key=lambda x:x[1],reverse=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKcagvyi0Wfk",
        "outputId": "da30061d-7e12-4f73-8cc6-c62b59c949e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('r', 13236), ('regression', 10959), ('machine learning', 6089), ('time series', 5559), ('probability', 4217), ('hypothesis testing', 3869), ('self study', 3732), ('distributions', 3501), ('logistic', 3316), ('classification', 2881), ('correlation', 2871), ('statistical significance', 2666), ('bayesian', 2656), ('anova', 2505), ('normal distribution', 2181), ('multiple regression', 2054), ('mixed model', 1998), ('clustering', 1952), ('neural networks', 1897), ('mathematical statistics', 1888), ('confidence interval', 1776), ('categorical data', 1703), ('generalized linear model', 1614), ('variance', 1576), ('data visualization', 1549), ('estimation', 1533), ('forecasting', 1422), ('t test', 1418), ('pca', 1395), ('sampling', 1363), ('cross validation', 1344), ('repeated measures', 1335), ('spss', 1296), ('svm', 1283), ('chi squared', 1261), ('maximum likelihood', 1209), ('predictive models', 1189), ('multivariate analysis', 1116), ('survival', 1081), ('references', 1076), ('data transformation', 1057), ('modeling', 1055), ('p value', 1040), ('feature selection', 997), ('econometrics', 989), ('panel data', 966), ('python', 955), ('data mining', 950), ('interaction', 946), ('matlab', 941), ('linear model', 937), ('binomial', 935), ('random forest', 935), ('nonparametric', 922), ('arima', 917), ('least squares', 898), ('optimization', 898), ('model selection', 876), ('standard deviation', 866), ('poisson', 865), ('interpretation', 860), ('sample size', 847), ('mean', 842), ('stata', 842), ('dataset', 840), ('conditional probability', 837), ('prediction', 832), ('multiple comparisons', 825), ('bootstrap', 814), ('experiment design', 780), ('random variable', 745), ('autocorrelation', 678), ('simulation', 676), ('covariance', 666), ('multilevel analysis', 663), ('pdf', 654), ('missing data', 652), ('expected value', 645), ('regression coefficients', 643), ('factor analysis', 642), ('mcmc', 635), ('outliers', 629), ('standard error', 629), ('inference', 625), ('ordinal', 624), ('survey', 617), ('deep learning', 600), ('cart', 593), ('residuals', 582), ('binary data', 570), ('random effects model', 569), ('goodness of fit', 567), ('model', 567), ('terminology', 551), ('stochastic processes', 530), ('nonlinear regression', 514), ('cox model', 510), ('monte carlo', 504), ('proportion', 503), ('algorithms', 500), ('sas', 496), ('lasso', 490), ('normalization', 484), ('heteroscedasticity', 483), ('error', 481), ('independence', 480), ('meta analysis', 480), ('multinomial', 480), ('k means', 465), ('lmer', 463), ('sample', 450), ('markov process', 445), ('scikit learn', 440), ('multicollinearity', 438), ('text mining', 432), ('aic', 431), ('descriptive statistics', 430), ('spatial', 429), ('assumptions', 418), ('matrix', 413), ('likelihood', 407), ('dimensionality reduction', 407), ('sem', 405), ('bias', 396), ('fixed effects model', 391), ('effect size', 375), ('logit', 374), ('r squared', 372), ('normality', 371), ('lme4', 371), ('convergence', 370), ('likert', 366), ('power analysis', 365), ('glmm', 359), ('negative binomial', 358), ('roc', 358), ('fitting', 357), ('computational statistics', 348), ('count data', 347), ('random generation', 345), ('prior', 340), ('summary statistics', 338), ('ranking', 338), ('stationarity', 337), ('natural language', 335), ('covariance matrix', 332), ('skewness', 325), ('kernel trick', 321), ('gamma distribution', 319), ('naive bayes', 318), ('continuous data', 317), ('regularization', 317), ('hidden markov model', 314), ('reliability', 314), ('power', 312), ('gaussian process', 310), ('group differences', 309), ('autoregressive', 307), ('biostatistics', 306), ('distance', 304), ('garch', 302), ('ancova', 300), ('causality', 300), ('standardization', 300), ('validation', 296), ('small sample', 295), ('exponential', 295), ('quantiles', 293), ('posterior', 291), ('var', 289), ('curve fitting', 288), ('post hoc', 284), ('kernel smoothing', 284), ('robust', 282), ('average', 277), ('gradient descent', 277), ('odds ratio', 275), ('lognormal', 275), ('median', 273), ('bayes', 273), ('seasonality', 270), ('expectation maximization', 270), ('uniform', 268), ('cointegration', 268), ('large data', 266), ('kolmogorov smirnov', 266), ('wilcoxon', 266), ('discrete data', 266), ('conv neural network', 264), ('gaussian mixture', 261), ('histogram', 260), ('non independent', 259), ('entropy', 259), ('pearson', 258), ('excel', 257), ('trend', 256), ('linear', 256), ('arma', 255), ('contingency tables', 253), ('joint distribution', 253), ('pattern recognition', 253), ('manova', 252), ('cdf', 250), ('scales', 248), ('unbalanced classes', 247), ('conditional expectation', 245), ('unbiased estimator', 245), ('mixture', 244), ('measurement error', 243), ('mann whitney u test', 242), ('boosting', 240), ('likelihood ratio', 238), ('data imputation', 238), ('hierarchical bayesian', 237), ('k nearest neighbour', 236), ('central limit theorem', 236), ('asymptotics', 236), ('discriminant analysis', 234), ('caret', 233), ('poisson regression', 233), ('unsupervised learning', 232), ('paired comparisons', 232), ('accuracy', 231), ('permutation', 231), ('graphical model', 231), ('psychometrics', 228), ('ridge regression', 228), ('instrumental variables', 227), ('image processing', 227), ('probit', 226), ('basic concepts', 226), ('similarities', 225), ('multiple imputation', 223), ('distance functions', 222), ('population', 219), ('overfitting', 217), ('predictor', 215), ('gibbs', 215), ('information theory', 212), ('recommender system', 206), ('feature construction', 206), ('estimators', 205), ('degrees of freedom', 205), ('glmnet', 202), ('jags', 201), ('finance', 200), ('gam', 199), ('epidemiology', 198), ('beta distribution', 198), ('proof', 198), ('moments', 198), ('notation', 196), ('linear algebra', 193), ('model comparison', 193), ('bayesian network', 192), ('nonlinear', 191), ('smoothing', 191), ('supervised learning', 191), ('approximation', 187), ('prediction interval', 185), ('cross correlation', 185), ('lme', 183), ('nested', 183), ('svd', 182), ('kalman filter', 180), ('fishers exact', 180), ('bernoulli distribution', 179), ('precision recall', 178), ('libsvm', 177), ('gee', 177), ('measurement', 177), ('latent variable', 177), ('loss functions', 176), ('contrasts', 176), ('zero inflation', 174), ('frequency', 174), ('splines', 173), ('logarithm', 172), ('t distribution', 172), ('auc', 172), ('censoring', 172), ('unit root', 172), ('resampling', 171), ('kruskal wallis', 170), ('intuition', 168), ('uncertainty', 165), ('order statistics', 165), ('hazard', 162), ('regression strategies', 162), ('mediation', 162), ('f test', 162), ('weka', 162), ('graph theory', 160), ('ensemble', 159), ('confirmatory factor', 157), ('definition', 156), ('glmer', 156), ('parametric', 155), ('copula', 155), ('combinatorics', 155), ('polynomial', 154), ('lm', 153), ('performance', 153), ('marginal', 153), ('software', 151), ('signal processing', 151), ('mutual information', 150), ('weighted regression', 150), ('propensity scores', 148), ('bonferroni', 148), ('multi class', 148), ('matching', 147), ('reinforcement learning', 145), ('diagnostic', 145), ('frequentist', 144), ('non stationary', 144), ('methodology', 142), ('genetics', 141), ('pymc', 141), ('dirichlet distribution', 140), ('bic', 139), ('stepwise regression', 139), ('metropolis hastings', 138), ('gbm', 138), ('analysis', 138), ('theory', 137), ('kullback leibler', 137), ('eigenvalues', 136), ('intraclass correlation', 135), ('inter rater', 134), ('paired data', 134), ('difference in difference', 133), ('metric', 132), ('hierarchical', 132), ('error propagation', 131), ('scatterplot', 131), ('multivariate regression', 131), ('interpolation', 130), ('quantile regression', 130), ('multidimensional scaling', 130), ('aggregation', 128), ('mse', 128), ('reporting', 128), ('hierarchical clustering', 128), ('weibull', 128), ('qq plot', 127), ('multivariate normal', 127), ('parameterization', 126), ('train', 126), ('change point', 125), ('irt', 124), ('matrix decomposition', 123), ('sparse', 123), ('topic models', 123), ('bioinformatics', 123), ('bivariate', 122), ('decision theory', 121), ('exponential smoothing', 121), ('lags', 120), ('backpropagation', 120), ('kurtosis', 120), ('poisson process', 119), ('state space models', 119), ('percentage', 119), ('randomization', 119), ('endogeneity', 118), ('ratio', 117), ('weighted mean', 116), ('z test', 116), ('eda', 116), ('spearman', 116), ('exponential family', 115), ('confidence', 115), ('nlme', 114), ('statistical learning', 114), ('probability inequalities', 114), ('false discovery rate', 113), ('networks', 112), ('convolution', 112), ('markov chain', 111), ('extreme value', 111), ('clinical trials', 110), ('autoencoders', 110), ('generalized least squares', 110), ('pls', 109), ('ecology', 109), ('boxplot', 109), ('hyperparameter', 109), ('sums of squares', 109), ('stratification', 109), ('learning', 108), ('teaching', 107), ('ab test', 107), ('conjugate prior', 106), ('sufficient statistics', 106), ('confounding', 106), ('consistency', 106), ('treatment effect', 105), ('ggplot2', 105), ('covariate', 104), ('bugs', 102), ('computer vision', 102), ('online', 100), ('coefficient', 99), ('randomness', 99), ('games', 98), ('granger causality', 98), ('weighted sampling', 98), ('kaplan meier', 97), ('high dimensional', 97), ('elastic net', 97), ('threshold', 96), ('sample mean', 94), ('lstm', 94), ('augmented dickey fuller', 94), ('fisher information', 94), ('rms', 93), ('pooling', 92), ('time varying covariate', 92), ('rpart', 92), ('spearman rho', 92), ('vecm', 92), ('hypergeometric', 92), ('moving average', 92), ('bounds', 92), ('maximum', 91), ('scores', 91), ('fourier transform', 90), ('integral', 90), ('overdispersion', 90), ('scipy', 90), ('type i errors', 90), ('power law', 89), ('residual analysis', 89), ('mathematics', 88), ('deviance', 88), ('binning', 88), ('interval', 87), ('psychology', 87), ('tukey hsd', 87), ('calibration', 87), ('rank correlation', 87), ('nominal', 86), ('intercept', 86), ('model evaluation', 86), ('information retrieval', 85), ('cross section', 85), ('partial correlation', 84), ('dice', 84), ('lme4 nlme', 84), ('z score', 84), ('genetic algorithms', 82), ('truncation', 81), ('partitioning', 81), ('weighted data', 81), ('quality control', 81), ('kappa', 81), ('importance', 80), ('log linear', 79), ('empirical', 79), ('function', 79), ('parameter optimization', 78), ('data preprocessing', 78), ('generalized moments', 77), ('association rules', 77), ('rnn', 77), ('social network', 77), ('sensitivity', 76), ('point estimation', 76), ('bagging', 76), ('matrix inverse', 76), ('java', 75), ('cohens d', 75), ('spectral analysis', 75), ('risk', 75), ('odds', 75), ('out of sample', 74), ('history', 74), ('association measure', 74), ('quadratic form', 74), ('random walk', 74), ('sequence analysis', 74), ('rbm', 74), ('filter', 74), ('centering', 73), ('control', 73), ('clustered standard errors', 73), ('link function', 73), ('maximum entropy', 73), ('deep belief networks', 72), ('artificial intelligence', 72), ('dirichlet process', 72), ('rare events', 72), ('validity', 71), ('mode', 71), ('confusion matrix', 71), ('meta regression', 71), ('pareto distribution', 70), ('winbugs', 70), ('observational study', 70), ('point process', 70), ('method comparison', 69), ('cluster sample', 68), ('circular statistics', 68), ('case control study', 68), ('segmentation', 68), ('shrinkage', 68), ('sequential analysis', 67), ('mcnemar test', 67), ('scoring', 67), ('kendall tau', 67), ('intervention analysis', 67), ('2sls', 66), ('fisher', 65), ('tobit regression', 65), ('loess', 65), ('volatility forecasting', 64), ('mgcv', 64), ('ranks', 64), ('beta binomial', 63), ('dynamic regression', 63), ('inferential statistics', 63), ('stan', 63), ('mice', 62), ('delta method', 62), ('rating', 62), ('iid', 61), ('moderation', 61), ('correspondence analysis', 61), ('anomaly detection', 61), ('method of moments', 61), ('equivalence', 61), ('relative risk', 61), ('hausman', 60), ('euclidean', 60), ('marketing', 60), ('noise', 60), ('minimum', 60), ('efficiency', 60), ('ordered logit', 60), ('numerical integration', 60), ('beta regression', 59), ('identifiability', 59), ('structural change', 59), ('geostatistics', 58), ('vif', 58), ('signal detection', 58), ('derivative', 58), ('traminer', 57), ('variational bayes', 57), ('tensorflow', 57), ('growth model', 57), ('coefficient of variation', 57), ('subset', 56), ('canonical correlation', 56), ('offset', 56), ('latent class', 56), ('spatio temporal', 55), ('multilabel', 55), ('adjustment', 55), ('cronbachs alpha', 55), ('white noise', 54), ('queueing', 54), ('credible interval', 54), ('composite', 53), ('philosophical', 53), ('statsmodels', 52), ('perceptron', 52), ('variogram', 52), ('statistical', 51), ('importance sampling', 51), ('variability', 51), ('mgf', 51), ('nls', 50), ('penalized', 50), ('numerics', 50), ('self organizing maps', 50), ('weights', 50), ('word2vec', 50), ('lsa', 49), ('finite population', 49), ('particle filter', 49), ('amos', 49), ('nonparametric bayes', 49), ('sensitivity analysis', 48), ('specificity', 48), ('education', 48), ('wishart', 48), ('levenes test', 48), ('gradient', 48), ('geometric distribution', 47), ('eviews', 47), ('lsmeans', 47), ('fuzzy', 47), ('density estimation', 46), ('minitab', 46), ('type ii errors', 46), ('robust standard error', 46), ('agreement statistics', 46), ('path model', 46), ('multivariable', 45), ('combining p values', 45), ('model based clustering', 45), ('programming', 45), ('arithmetic', 45), ('word embeddings', 44), ('geometry', 44), ('replication', 44), ('split plot', 44), ('gini', 44), ('microarray', 44), ('blocking', 44), ('rejection sampling', 43), ('macroeconomics', 43), ('constrained regression', 43), ('log likelihood', 43), ('multiarmed bandit', 42), ('code', 42), ('change scores', 42), ('imbalanced', 42), ('brownian', 42), ('clogit', 42), ('conjoint analysis', 42), ('univariate', 42), ('mixed design', 42), ('arch', 41), ('lavaan', 41), ('application', 41), ('jmp', 41), ('conditioning', 41), ('communication', 40), ('z statistic', 40), ('barplot', 40), ('semi supervised', 40), ('measure theory', 40), ('summations', 40), ('data cleaning', 40), ('tables', 39), ('impulse response', 39), ('demography', 39), ('generative models', 39), ('f distribution', 39), ('functional data analysis', 38), ('dlm', 38), ('sentiment analysis', 38), ('curves', 38), ('reproducible research', 38), ('c++', 38), ('back transformation', 38), ('logrank', 37), ('fat tails', 37), ('survey weights', 37), ('umvue', 37), ('mlogit', 37), ('package', 37), ('friedman test', 37), ('plm', 37), ('wavelet', 37), ('fractional factorial', 37), ('uninformative prior', 35), ('cauchy', 35), ('law of large numbers', 35), ('kriging', 35), ('marginal effect', 35), ('signed rank test', 34), ('lars', 34), ('bias correction', 34), ('mathematica', 34), ('formula', 34), ('ica', 34), ('valuation', 33), ('discontinuity', 33), ('projection', 33), ('multiple seasonalities', 33), ('hauck donner effect', 33), ('cosine similarity', 33), ('rotation', 33), ('census', 32), ('heterogeneity', 32), ('dendrogram', 32), ('biplot', 32), ('cholesky', 32), ('radial basis', 32), ('interval censoring', 32), ('error message', 31), ('careers', 31), ('crossover study', 31), ('numpy', 31), ('softmax', 31), ('rule of thumb', 31), ('real time', 31), ('f statistic', 31), ('mplus', 31), ('two way', 31), ('factor rotation', 31), ('anderson darling', 31), ('ecdf', 31), ('web', 31), ('parallel computing', 30), ('piecewise linear', 30), ('igraph', 30), ('oversampling', 30), ('range', 30), ('adaboost', 30), ('dataframe', 30), ('test for trend', 30), ('random matrix', 30), ('dispersion', 30), ('inverse gamma', 29), ('laplace distribution', 29), ('jaccard similarity', 29), ('e1071', 29), ('effects', 29), ('computing', 29), ('business intelligence', 29), ('incidence rate ratio', 29), ('bayes factors', 29), ('heavy tailed', 29), ('errors in variables', 29), ('heckman', 28), ('neyman pearson lemma', 28), ('transition matrix', 28), ('quasi likelihood', 28), ('discriminant', 28), ('model averaging', 28), ('frailty', 28), ('sphericity', 28), ('chemometrics', 28), ('statistical control', 28), ('constraint', 28), ('scale invariance', 28), ('stacking', 27), ('optimal scaling', 27), ('vc dimension', 27), ('social science', 27), ('k medoids', 27), ('moving window', 27), ('indicator variables', 27), ('tolerance interval', 26), ('poisson binomial', 26), ('conditional random field', 26), ('non response', 26), ('correlated predictors', 26), ('nnet', 26), ('apriori', 26), ('spark mllib', 26), ('tbats', 26), ('chow test', 26), ('segmented regression', 26), ('coding', 25), ('total least squares', 25), ('profile likelihood', 25), ('theano', 25), ('interaction variable', 25), ('control chart', 25), ('truncated normal', 25), ('mad', 25), ('cosine distance', 25), ('information', 24), ('big data', 24), ('partial', 24), ('concordance', 24), ('jackknife', 24), ('dropout', 24), ('rapidminer', 24), ('units', 24), ('churn', 24), ('qualitative', 24), ('survey sampling', 24), ('precision', 24), ('trimmed mean', 24), ('time complexity', 23), ('correlation matrix', 23), ('probabilistic programming', 23), ('ecm', 23), ('repeatability', 23), ('leverage', 23), ('subsampling', 23), ('funnel plot', 23), ('convex', 23), ('dunn test', 23), ('jeffreys prior', 23), ('kde', 23), ('sql', 23), ('gumbel', 23), ('characteristic function', 23), ('age', 23), ('representative', 23), ('bimodal', 22), ('skew normal', 22), ('compositional data', 22), ('presentation', 22), ('neuroscience', 22), ('pandas', 22), ('interactive visualization', 22), ('neweywest', 22), ('integration', 22), ('causalimpact', 21), ('finite mixture model', 21), ('non central', 21), ('synthetic data', 21), ('paradox', 21), ('ergodic', 21), ('zero inflated', 21), ('capture mark recapture', 21), ('events', 21), ('sequential pattern mining', 21), ('two step estimation', 21), ('choice', 21), ('geometric mean', 21), ('neuroimaging', 21), ('martingale', 20), ('symmetry', 20), ('c#', 20), ('deming regression', 20), ('optimal stopping', 20), ('publication bias', 20), ('familywise error', 20), ('simpsons paradox', 20), ('interarrival time', 20), ('multivariate distribution', 20), ('taylor series', 20), ('hotelling', 20), ('failure', 20), ('average precision', 20), ('cost maximization', 20), ('determinant', 20), ('project management', 20), ('mancova', 20), ('polling', 19), ('nonparametric regression', 19), ('language models', 19), ('matplotlib', 19), ('compression', 19), ('coverage probability', 19), ('abc', 19), ('competing risks', 19), ('singular', 19), ('bernoulli process', 19), ('fraud', 19), ('box jenkins', 19), ('nnmf', 19), ('decomposition', 19), ('xgboost', 19), ('standard', 19), ('cross entropy', 19), ('elasticity', 19), ('database', 18), ('operations research', 18), ('variance decomposition', 18), ('phylogeny', 18), ('scoring rules', 18), ('hessian', 18), ('differences', 18), ('tsne', 18), ('zipf', 18), ('pivot', 17), ('non nested', 17), ('data association', 17), ('cfa', 17), ('directional statistics', 17), ('overlapping data', 17), ('steins phenomenon', 17), ('recurrent events', 17), ('sign test', 17), ('heatmap', 17), ('planned comparisons test', 17), ('fisher transform', 17), ('academia', 17), ('dbscan', 17), ('tost', 17), ('proportional hazards', 16), ('underdispersion', 16), ('open bugs', 16), ('manifold learning', 16), ('fuzzy set', 16), ('one class', 16), ('linearity', 16), ('coupon collector problem', 16), ('sandwich', 16), ('mape', 16), ('cramers v', 16), ('reml', 16), ('index decomposition', 15), ('gis', 15), ('inequality', 15), ('rbf network', 15), ('heuristic', 15), ('gamm4', 15), ('lrt', 15), ('matrix calculus', 15), ('dependence', 15), ('climate', 15), ('extrapolation', 15), ('rasch', 15), ('dag', 15), ('fractal', 15), ('exact test', 15), ('mortality', 15), ('differential equations', 15), ('transform', 14), ('data generating process', 14), ('bland altman plot', 14), ('stochastic approximation', 14), ('elections', 14), ('collaborative', 14), ('homogeneity', 14), ('suppressor', 14), ('sgd', 14), ('recursive model', 14), ('interquartile', 14), ('geography', 14), ('gwas', 14), ('rayleigh', 14), ('relative distribution', 14), ('viterbi algorithm', 14), ('pie chart', 14), ('birthday paradox', 13), ('semiparametric', 13), ('nonlinearity', 13), ('breusch pagan', 13), ('discussion', 13), ('jacobian', 13), ('benchmark', 13), ('latent semantic indexing', 13), ('underdetermined', 13), ('explanatory', 13), ('skellam', 13), ('pcoa', 13), ('game theory', 13), ('quasi binomial', 13), ('distance covariance', 13), ('cochran mantel haenszel', 13), ('open source', 12), ('q learning', 12), ('nonparametric density', 12), ('statistical bias', 12), ('markov random field', 12), ('library', 12), ('invariance', 12), ('journals', 12), ('gamlss', 12), ('order', 12), ('inverse gaussian distrib', 12), ('cochran q', 12), ('two sample', 12), ('case cohort', 12), ('error in variables', 12), ('novelty detection', 12), ('mean shift', 12), ('growth mixture model', 12), ('checking', 12), ('quasi monte carlo', 11), ('search theory', 11), ('information geometry', 11), ('latex', 11), ('partial plot', 11), ('regression to the mean', 11), ('mars', 11), ('automatic algorithms', 11), ('l moments', 11), ('nltk', 11), ('vector fields', 11), ('labeling', 11), ('linear dynamical system', 11), ('dependent', 11), ('systematic', 11), ('mase', 11), ('spurious correlation', 11), ('network meta analysis', 11), ('environmental data', 11), ('latin hypercube', 11), ('point mass at zero', 11), ('medicine', 11), ('mae', 10), ('disease', 10), ('optimal', 10), ('discrete time', 10), ('twin', 10), ('politics', 10), ('blue', 10), ('yates correction', 10), ('bradley terry model', 10), ('contrast', 10), ('baum welch', 10), ('expectation', 10), ('condition number', 10), ('modularity', 10), ('irls', 10), ('minimax', 10), ('counterbalancing', 10), ('dyadic data', 10), ('topologies', 10), ('javascript', 10), ('armax', 10), ('local statistics', 10), ('tweedie distribution', 10), ('bayesian optimization', 10), ('sur', 10), ('pre training', 10), ('gambling', 10), ('minimum variance', 10), ('torch', 10), ('gretl', 10), ('rao blackwell', 10), ('science', 9), ('life expectancy', 9), ('csv file', 9), ('vowpal wabbit', 9), ('belief propagation', 9), ('puzzle', 9), ('rocr', 9), ('scale construction', 9), ('approximate inference', 9), ('car', 9), ('poker', 9), ('sweave', 9), ('ordered probit', 9), ('starting values', 9), ('variance stabilizing', 9), ('scale estimator', 9), ('scalability', 9), ('glmmlasso', 9), ('party', 9), ('elo', 9), ('down sample', 9), ('active learning', 9), ('ward', 9), ('multitask learning', 9), ('population average', 9), ('linear programming', 9), ('schoenfeld residuals', 9), ('products', 9), ('crostons method', 9), ('separability', 9), ('pareto', 9), ('permutation test', 8), ('elicitation', 8), ('randomized', 8), ('moment', 8), ('julia', 8), ('absolute risk', 8), ('item analysis', 8), ('score function', 8), ('tf idf', 8), ('parallel analysis', 8), ('knowledge discovery', 8), ('spatial interaction model', 8), ('shape', 8), ('ruby', 8), ('explanatory models', 8), ('multinomial logit', 8), ('fallacy', 8), ('partykit', 8), ('probability calculus', 8), ('sigma algebra', 8), ('in sample', 8), ('marginal model', 8), ('statistics in media', 8), ('nlmer', 8), ('latin square', 8), ('internet', 8), ('logic', 8), ('mfcc', 8), ('prediction limit', 8), ('numerical models', 8), ('diffusion', 8), ('inverse cdf', 8), ('pmml', 8), ('pivot table', 7), ('treatment', 7), ('enrichment', 7), ('batch normalization', 7), ('saddlepoint approximation', 7), ('non inferiority', 7), ('probability generating fn', 7), ('contextual bandit', 7), ('max margin', 7), ('hac', 7), ('visual summary', 7), ('reduced rank regression', 7), ('lifetable', 7), ('chemistry', 7), ('runs', 7), ('identification', 7), ('lilliefors', 7), ('polr', 7), ('replicate', 7), ('courses', 7), ('gllamm', 7), ('combinatorial', 7), ('etymology', 7), ('hosmer lemeshow test', 7), ('musical data analysis', 6), ('mixed distribution', 6), ('lorenz curve', 6), ('likelihood ratio test', 6), ('astronomy', 6), ('isotonic', 6), ('phd', 6), ('ellipse', 6), ('restrictions', 6), ('missing value', 6), ('untagged', 6), ('stochastic ordering', 6), ('simultaneous equation', 6), ('fiducial', 6), ('population ecology', 6), ('blup', 6), ('gpower', 6), ('bayes optimal classifier', 6), ('structured svm', 6), ('value of information', 6), ('community wiki', 6), ('adagrad', 6), ('php', 6), ('coda', 6), ('gnuplot', 6), ('admissibility', 6), ('pruning', 6), ('bayesian score', 5), ('derived distributions', 5), ('regression testing', 5), ('engineering statistics', 5), ('voting system', 5), ('hotelling t2', 5), ('normalizing constant', 5), ('exchangeability', 5), ('spss modeler', 5), ('domain adaptation', 5), ('rlm', 5), ('information extraction', 5), ('circular', 5), ('diagnosis', 5), ('deterministic', 5), ('gamboost', 5), ('normal approximation', 5), ('bessels correction', 5), ('reproducibility', 5), ('google spreadsheet', 5), ('extremal dependence', 5), ('m estimation', 5), ('casella berger', 5), ('absolute deviation', 5), ('cv.glm', 5), ('cumulants', 5), ('fisher scoring', 5), ('monitoring', 4), ('logarithmic series', 4), ('combining estimates', 4), ('transportation', 4), ('design based inference', 4), ('forecastability', 4), ('conferences', 4), ('polychoric', 4), ('smallareaestimation', 4), ('forward backward', 4), ('disaggregation', 4), ('d prime', 4), ('splus', 4), ('gui', 4), ('named entity recognition', 4), ('gru', 4), ('pybrain', 4), ('differential privacy', 4), ('double blind', 4), ('improper prior', 4), ('structured prediction', 4), ('abbreviation', 4), ('calc', 4), ('combining predictions', 4), ('orthogonal', 4), ('anosim', 4), ('ronald fisher', 4), ('general additive model', 4), ('dropconnect', 4), ('multiple membership', 4), ('tensor', 4), ('hmc', 4), ('quotation', 4), ('bias node', 4), ('consulting', 4), ('compartmental models', 4), ('algebraic statistics', 3), ('auxiliary variable', 3), ('multicore', 3), ('unit information prior', 3), ('dplyr', 3), ('cooccurrence', 3), ('slutsky theorem', 3), ('infinite variance', 3), ('gpu', 3), ('frequency severity', 3), ('rademacher complexity', 3), ('perl', 3), ('clara', 3), ('subject specific', 3), ('sigmoid', 3), ('example', 3), ('multinomial probit', 3), ('nnt', 3), ('empirical likelihood', 3), ('log loss', 3), ('rounding', 3), ('collecting data', 3), ('chi distribution', 3), ('complete statistics', 3), ('dunnett', 3), ('kolmogorov axioms', 3), ('np', 3), ('generalized eta squared', 3), ('ancillary statistics', 3), ('intractable likelihood', 3), ('optunity', 3), ('fortran', 3), ('systematic review', 3), ('reversible jump', 3), ('timelines', 3), ('nadaraya watson', 3), ('crossover', 3), ('humor', 2), ('concavity', 2), ('geomarketing', 2), ('plyr', 2), ('regularity', 2), ('referee', 2), ('generator', 2), ('rough sets', 2), ('rhadoop', 2), ('add one smoothing', 2), ('theta method', 2), ('factorisation theorem', 2), ('xorshift', 2), ('legal', 2), ('risk difference', 2), ('oracle', 2), ('automatic differentiation', 2), ('ipf', 2), ('model checking', 2), ('lyapunov exponent', 2), ('tweedie', 2), ('wald estimator', 2), ('toeplitz', 2), ('qr', 2), ('cubic', 2), ('duan smearing', 2), ('dic', 2), ('pitch game', 2), ('shortest half', 2), ('transfer learning', 2), ('statistical theory', 2), ('volatility', 2), ('potts model', 2), ('calculus', 2), ('als', 2), ('bag of words', 2), ('approximate randomization', 2), ('drug', 2), ('therapy', 2), ('evolutionary algorithms', 2), ('rmr', 2), ('variance test', 2), ('test equating', 2), ('characterization', 2), ('2d', 1), ('protovis', 1), ('pspp', 1), ('qsar', 1), ('netflix prize', 1), ('bnlearn', 1), ('bayesian anova', 1), ('inliers', 1), ('auxiliary particle filter', 1), ('hierarchical softmax', 1), ('law of total expectation', 1), ('langevin diffusion', 1), ('quartile', 1), ('segmented', 1), ('svmlibsm', 1), ('fused lasso', 1), ('gmm', 1), ('american community survey', 1), ('mechanism design', 1), ('representation learning', 1), ('propensity', 1), ('mcar', 1), ('combining models', 1), ('leave one out', 1), ('gmmboost', 1), ('dimensions', 1), ('fda', 1), ('corpus linguistics', 1), ('pit', 1), ('mboost', 1), ('memm', 1), ('fmincon', 1), ('capability certification', 1), ('mean deviation', 1), ('mean absolute deviation', 1), ('doc2vec', 1), ('network layout', 1), ('shapley value', 1), ('adversarial boosting', 1), ('sympy', 1), ('matconvnet', 1), ('negative results', 1), ('hawkes', 1), ('retrospective', 1), ('ram', 1), ('replicability', 1), ('efficacy', 1), ('bands', 1), ('concept drift', 1), ('clumping', 1), ('markov logic network', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "freq.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PQMi8WIv0_u",
        "outputId": "909950b5-817b-45f3-9a44-e1c712baa0eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['r',\n",
              " 'regression',\n",
              " 'machine learning',\n",
              " 'time series',\n",
              " 'probability',\n",
              " 'hypothesis testing',\n",
              " 'self study',\n",
              " 'distributions',\n",
              " 'logistic',\n",
              " 'classification']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Top 10 most frequent tags\n",
        "common_tags = list(freq.keys())[:10]\n",
        "common_tags"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "kI3ctnM_fpo2",
        "outputId": "2290a450-31c3-4680-98bc-06c2161ff60b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Id  \\\n",
              "0    6   \n",
              "1   21   \n",
              "2   22   \n",
              "3   31   \n",
              "4   36   \n",
              "5   93   \n",
              "6   95   \n",
              "7  103   \n",
              "8  113   \n",
              "9  114   \n",
              "\n",
              "                                                                                                                                                                                                      Body  \\\n",
              "0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...   \n",
              "1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...   \n",
              "2                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n   \n",
              "3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....   \n",
              "4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...   \n",
              "5  <p>We're trying to use a Gaussian process to model h(t) -- the hazard function -- for a very small initial population, and then fit that using the available data.  While this gives us nice plots f...   \n",
              "6  <p>I have been using various GARCH-based models to forecast volatility for various North American equities using historical daily data as inputs.</p>\\n\\n<p>Asymmetric GARCH models are often cited ...   \n",
              "7  <p>What is the best blog on data visualization?</p>\\n\\n<p>I'm making this question a community wiki since it is highly subjective.  Please limit each answer to one link.</p>\\n\\n<hr>\\n\\n<p><strong>...   \n",
              "8  <p>I have been looking into theoretical frameworks for method selection (note: not model selection) and have found very little systematic, mathematically-motivated work. By 'method selection', I m...   \n",
              "9                                                                                                                                   <p>What statistical research blogs would you recommend, and why?</p>\\n   \n",
              "\n",
              "                                                                                                                                                                                              cleaned_text  \\\n",
              "0  last year i read a blog post from brendan o connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to ...   \n",
              "1  what are some of the ways to forecast demographic census with some validation and calibration techniques some of the concerns census blocks vary in sizes as rural areas are a lot larger than conde...   \n",
              "2                                                                                         how would you describe in plain english the characteristics that distinguish bayesian from frequentist reasoning   \n",
              "3  after taking a statistics course and then trying to help fellow students i noticed one subject that inspires much head desk banging is interpreting the results of statistical hypothesis tests it s...   \n",
              "4  there is an old saying correlation does not mean causation when i teach i tend to use the following standard examples to illustrate this point number of storks and birth rate in denmark number of ...   \n",
              "5  we re trying to use a gaussian process to model h t the hazard function for a very small initial population and then fit that using the available data while this gives us nice plots for credible s...   \n",
              "6  i have been using various garch based models to forecast volatility for various north american equities using historical daily data as inputs asymmetric garch models are often cited as a modificat...   \n",
              "7  what is the best blog on data visualization i m making this question a community wiki since it is highly subjective please limit each answer to one link please note the following criteria for prop...   \n",
              "8  i have been looking into theoretical frameworks for method selection note not model selection and have found very little systematic mathematically motivated work by method selection i mean a frame...   \n",
              "9                                                                                                                                              what statistical research blogs would you recommend and why   \n",
              "\n",
              "                                                               tags  \n",
              "0                                                [machine learning]  \n",
              "1                                 [forecasting, population, census]  \n",
              "2                                           [bayesian, frequentist]  \n",
              "3  [hypothesis testing, t test, p value, interpretation, intuition]  \n",
              "4                                           [correlation, teaching]  \n",
              "5                                 [nonparametric, survival, hazard]  \n",
              "6             [time series, garch, volatility forecasting, finance]  \n",
              "7                                  [data visualization, references]  \n",
              "8                           [machine learning, methodology, theory]  \n",
              "9                                                      [references]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-702d17df-8bee-4b5d-b8af-5e75dc1ced70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Body</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n",
              "      <td>last year i read a blog post from brendan o connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to ...</td>\n",
              "      <td>[machine learning]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n",
              "      <td>what are some of the ways to forecast demographic census with some validation and calibration techniques some of the concerns census blocks vary in sizes as rural areas are a lot larger than conde...</td>\n",
              "      <td>[forecasting, population, census]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
              "      <td>how would you describe in plain english the characteristics that distinguish bayesian from frequentist reasoning</td>\n",
              "      <td>[bayesian, frequentist]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n",
              "      <td>after taking a statistics course and then trying to help fellow students i noticed one subject that inspires much head desk banging is interpreting the results of statistical hypothesis tests it s...</td>\n",
              "      <td>[hypothesis testing, t test, p value, interpretation, intuition]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n",
              "      <td>there is an old saying correlation does not mean causation when i teach i tend to use the following standard examples to illustrate this point number of storks and birth rate in denmark number of ...</td>\n",
              "      <td>[correlation, teaching]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>93</td>\n",
              "      <td>&lt;p&gt;We're trying to use a Gaussian process to model h(t) -- the hazard function -- for a very small initial population, and then fit that using the available data.  While this gives us nice plots f...</td>\n",
              "      <td>we re trying to use a gaussian process to model h t the hazard function for a very small initial population and then fit that using the available data while this gives us nice plots for credible s...</td>\n",
              "      <td>[nonparametric, survival, hazard]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>95</td>\n",
              "      <td>&lt;p&gt;I have been using various GARCH-based models to forecast volatility for various North American equities using historical daily data as inputs.&lt;/p&gt;\\n\\n&lt;p&gt;Asymmetric GARCH models are often cited ...</td>\n",
              "      <td>i have been using various garch based models to forecast volatility for various north american equities using historical daily data as inputs asymmetric garch models are often cited as a modificat...</td>\n",
              "      <td>[time series, garch, volatility forecasting, finance]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>103</td>\n",
              "      <td>&lt;p&gt;What is the best blog on data visualization?&lt;/p&gt;\\n\\n&lt;p&gt;I'm making this question a community wiki since it is highly subjective.  Please limit each answer to one link.&lt;/p&gt;\\n\\n&lt;hr&gt;\\n\\n&lt;p&gt;&lt;strong&gt;...</td>\n",
              "      <td>what is the best blog on data visualization i m making this question a community wiki since it is highly subjective please limit each answer to one link please note the following criteria for prop...</td>\n",
              "      <td>[data visualization, references]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>113</td>\n",
              "      <td>&lt;p&gt;I have been looking into theoretical frameworks for method selection (note: not model selection) and have found very little systematic, mathematically-motivated work. By 'method selection', I m...</td>\n",
              "      <td>i have been looking into theoretical frameworks for method selection note not model selection and have found very little systematic mathematically motivated work by method selection i mean a frame...</td>\n",
              "      <td>[machine learning, methodology, theory]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>114</td>\n",
              "      <td>&lt;p&gt;What statistical research blogs would you recommend, and why?&lt;/p&gt;\\n</td>\n",
              "      <td>what statistical research blogs would you recommend and why</td>\n",
              "      <td>[references]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-702d17df-8bee-4b5d-b8af-5e75dc1ced70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-702d17df-8bee-4b5d-b8af-5e75dc1ced70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-702d17df-8bee-4b5d-b8af-5e75dc1ced70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a31231b8-258b-4067-9342-4c53085e67c7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a31231b8-258b-4067-9342-4c53085e67c7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a31231b8-258b-4067-9342-4c53085e67c7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buPS2OrlN50F"
      },
      "source": [
        "We will use only those questions/queries that have the above 10 tags associated with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "CVB3DKppym51"
      },
      "outputs": [],
      "source": [
        "x=[]\n",
        "y=[]\n",
        "\n",
        "for i in range(len(df['tags'])):\n",
        "\n",
        "  temp=[]\n",
        "  for j in df['tags'][i]:\n",
        "    if j in common_tags:\n",
        "      temp.append(j)\n",
        "\n",
        "\n",
        "  if(len(temp)>1):\n",
        "    x.append(df['cleaned_text'][i])\n",
        "    y.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbq7fbFxZ0Ib",
        "outputId": "9dc0cb80-8af6-4603-d718-5efcf60ce170"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hypothesis testing']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYMxubGzzN7Q",
        "outputId": "f48ec2c9-2c6d-45af-90fc-1ca11d598556"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11106"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# number of questions left\n",
        "len(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m7o1vIMaJHY",
        "outputId": "b1c83ea5-9588-4a6f-e678-c88d52339405"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['r', 'time series'],\n",
              " ['regression', 'distributions'],\n",
              " ['distributions', 'probability', 'hypothesis testing'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['r', 'time series', 'self study'],\n",
              " ['probability', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['regression', 'time series'],\n",
              " ['time series', 'hypothesis testing'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['machine learning', 'logistic'],\n",
              " ['regression', 'probability', 'logistic'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['r', 'regression', 'hypothesis testing'],\n",
              " ['r', 'machine learning'],\n",
              " ['machine learning', 'classification'],\n",
              " ['probability', 'self study'],\n",
              " ['probability', 'distributions'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'time series', 'machine learning', 'hypothesis testing'],\n",
              " ['machine learning', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'distributions'],\n",
              " ['machine learning', 'probability', 'classification'],\n",
              " ['r', 'machine learning'],\n",
              " ['probability', 'self study'],\n",
              " ['machine learning', 'hypothesis testing', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'classification'],\n",
              " ['self study', 'classification'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'machine learning'],\n",
              " ['probability', 'distributions', 'self study'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['machine learning', 'logistic'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['regression', 'logistic'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['hypothesis testing', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'distributions'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'machine learning'],\n",
              " ['time series', 'probability'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'regression', 'machine learning'],\n",
              " ['r', 'distributions'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'self study'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'regression', 'hypothesis testing'],\n",
              " ['regression', 'logistic'],\n",
              " ['time series', 'self study'],\n",
              " ['regression', 'time series'],\n",
              " ['machine learning', 'probability'],\n",
              " ['regression', 'classification'],\n",
              " ['regression', 'machine learning'],\n",
              " ['regression', 'logistic', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['time series', 'machine learning'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'probability'],\n",
              " ['r', 'probability'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['regression', 'machine learning', 'distributions'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'machine learning'],\n",
              " ['r', 'logistic'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression', 'machine learning'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'self study'],\n",
              " ['machine learning', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'distributions'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'distributions'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['probability', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['time series', 'probability', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'logistic'],\n",
              " ['time series', 'self study'],\n",
              " ['hypothesis testing', 'distributions'],\n",
              " ['self study', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'time series', 'hypothesis testing', 'self study'],\n",
              " ['r', 'machine learning'],\n",
              " ['regression', 'machine learning', 'time series'],\n",
              " ['time series', 'machine learning'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'machine learning'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['time series', 'distributions', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['time series', 'distributions'],\n",
              " ['regression', 'time series'],\n",
              " ['regression', 'logistic'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'distributions'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'self study'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['machine learning', 'classification'],\n",
              " ['probability', 'self study'],\n",
              " ['probability', 'distributions', 'self study'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['probability', 'self study'],\n",
              " ['regression', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['logistic', 'classification'],\n",
              " ['regression', 'time series'],\n",
              " ['distributions', 'probability'],\n",
              " ['hypothesis testing', 'logistic'],\n",
              " ['machine learning', 'r'],\n",
              " ['r', 'logistic'],\n",
              " ['classification', 'logistic'],\n",
              " ['probability', 'self study'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'machine learning', 'logistic'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'machine learning', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['regression', 'machine learning'],\n",
              " ['r', 'machine learning'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['time series', 'probability'],\n",
              " ['r', 'distributions'],\n",
              " ['regression', 'probability'],\n",
              " ['r', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['time series', 'hypothesis testing'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'machine learning'],\n",
              " ['probability', 'distributions'],\n",
              " ['regression', 'machine learning'],\n",
              " ['r', 'time series'],\n",
              " ['time series', 'machine learning', 'hypothesis testing'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'machine learning'],\n",
              " ['r', 'machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression', 'classification'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'self study'],\n",
              " ['regression', 'time series'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'hypothesis testing'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'time series', 'machine learning'],\n",
              " ['r', 'classification'],\n",
              " ['regression', 'time series'],\n",
              " ['machine learning', 'probability'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'distributions'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'distributions', 'probability'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'machine learning', 'logistic'],\n",
              " ['distributions', 'hypothesis testing'],\n",
              " ['r', 'distributions'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'self study'],\n",
              " ['probability', 'distributions'],\n",
              " ['regression', 'machine learning'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'regression', 'hypothesis testing'],\n",
              " ['probability', 'self study'],\n",
              " ['machine learning', 'probability', 'classification'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['r', 'probability'],\n",
              " ['probability', 'self study'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'self study', 'logistic'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'probability'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'distributions'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['machine learning', 'logistic'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['machine learning', 'classification'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'machine learning'],\n",
              " ['regression', 'machine learning'],\n",
              " ['probability', 'self study'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'self study'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'time series'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'machine learning'],\n",
              " ['r', 'regression'],\n",
              " ['distributions', 'classification'],\n",
              " ['time series', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'machine learning'],\n",
              " ['probability', 'distributions'],\n",
              " ['distributions', 'probability'],\n",
              " ['r', 'regression', 'self study'],\n",
              " ['regression', 'time series'],\n",
              " ['r', 'logistic'],\n",
              " ['time series', 'hypothesis testing'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'time series', 'machine learning'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'time series', 'machine learning'],\n",
              " ['r', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'self study'],\n",
              " ['hypothesis testing', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['regression', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'time series'],\n",
              " ['hypothesis testing', 'logistic'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['regression', 'probability', 'logistic'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'distributions'],\n",
              " ['distributions', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'distributions', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['hypothesis testing', 'distributions'],\n",
              " ['time series', 'probability'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'time series'],\n",
              " ['r', 'classification'],\n",
              " ['machine learning', 'probability'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'probability'],\n",
              " ['regression', 'probability', 'self study'],\n",
              " ['distributions', 'self study'],\n",
              " ['regression', 'hypothesis testing'],\n",
              " ['r', 'logistic'],\n",
              " ['machine learning', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'hypothesis testing', 'self study'],\n",
              " ['r', 'probability', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'classification'],\n",
              " ['logistic', 'classification'],\n",
              " ['time series', 'hypothesis testing'],\n",
              " ['regression', 'hypothesis testing'],\n",
              " ['regression', 'distributions', 'probability'],\n",
              " ['time series', 'self study'],\n",
              " ['regression', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'logistic'],\n",
              " ['regression', 'time series', 'hypothesis testing', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'probability', 'logistic'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'time series'],\n",
              " ['regression', 'self study'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'distributions'],\n",
              " ['machine learning', 'self study', 'classification'],\n",
              " ['probability', 'self study'],\n",
              " ['time series', 'probability'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'self study'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'distributions'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'machine learning', 'classification'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['hypothesis testing', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'probability'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['machine learning', 'logistic', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'probability'],\n",
              " ['regression', 'classification'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['machine learning', 'probability'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'classification'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['probability', 'distributions'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'time series', 'logistic', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['time series', 'machine learning'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'time series'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'time series'],\n",
              " ['time series', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'logistic'],\n",
              " ['regression', 'machine learning'],\n",
              " ['regression', 'machine learning'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'self study'],\n",
              " ['distributions', 'self study'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['regression', 'hypothesis testing', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'probability'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['hypothesis testing', 'logistic'],\n",
              " ['time series', 'hypothesis testing'],\n",
              " ['time series', 'probability'],\n",
              " ['regression', 'logistic'],\n",
              " ['time series', 'hypothesis testing'],\n",
              " ['r', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'probability'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'machine learning'],\n",
              " ['probability', 'distributions', 'self study'],\n",
              " ['r', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['r', 'machine learning'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'probability'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['logistic', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['regression', 'logistic'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['regression', 'time series'],\n",
              " ['probability', 'self study', 'distributions'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['regression', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'hypothesis testing'],\n",
              " ['probability', 'distributions'],\n",
              " ['machine learning', 'logistic'],\n",
              " ['r', 'regression', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'probability'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['machine learning', 'classification'],\n",
              " ['classification', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'logistic', 'classification'],\n",
              " ['probability', 'self study'],\n",
              " ['probability', 'hypothesis testing'],\n",
              " ['distributions', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'machine learning', 'time series'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['r', 'regression', 'time series', 'machine learning'],\n",
              " ['logistic', 'classification'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['distributions', 'hypothesis testing'],\n",
              " ['probability', 'self study'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['machine learning', 'probability', 'classification'],\n",
              " ['probability', 'self study', 'distributions'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'logistic'],\n",
              " ['machine learning', 'probability', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['distributions', 'self study'],\n",
              " ['probability', 'distributions'],\n",
              " ['regression', 'time series'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'self study'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'distributions'],\n",
              " ['machine learning', 'self study'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'probability', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'logistic'],\n",
              " ['regression', 'time series'],\n",
              " ['machine learning', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'regression', 'probability'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'time series', 'logistic'],\n",
              " ['r', 'machine learning', 'distributions'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['time series', 'distributions'],\n",
              " ['hypothesis testing', 'distributions'],\n",
              " ['regression', 'time series'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'self study'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['machine learning', 'logistic', 'classification'],\n",
              " ['r', 'machine learning'],\n",
              " ['regression', 'machine learning'],\n",
              " ['distributions', 'probability'],\n",
              " ['probability', 'self study'],\n",
              " ['distributions', 'regression'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['time series', 'hypothesis testing'],\n",
              " ['regression', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'probability', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'hypothesis testing'],\n",
              " ['logistic', 'classification'],\n",
              " ['regression', 'hypothesis testing'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'classification'],\n",
              " ['regression', 'machine learning'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['distributions', 'self study'],\n",
              " ['machine learning', 'classification'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'logistic'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'self study'],\n",
              " ['regression', 'self study'],\n",
              " ['time series', 'self study'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'machine learning', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['probability', 'distributions'],\n",
              " ['regression', 'probability'],\n",
              " ['regression', 'time series', 'self study'],\n",
              " ['time series', 'machine learning'],\n",
              " ['r', 'regression', 'distributions'],\n",
              " ['time series', 'probability'],\n",
              " ['r', 'machine learning', 'self study'],\n",
              " ['machine learning', 'classification'],\n",
              " ['machine learning', 'classification', 'regression'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'self study'],\n",
              " ['regression', 'self study'],\n",
              " ['regression', 'self study'],\n",
              " ['regression', 'logistic'],\n",
              " ['logistic', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'machine learning'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'self study', 'distributions'],\n",
              " ['probability', 'hypothesis testing', 'distributions'],\n",
              " ['r', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['machine learning', 'probability', 'classification'],\n",
              " ['distributions', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['machine learning', 'logistic', 'classification'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['hypothesis testing', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'machine learning'],\n",
              " ['regression', 'machine learning'],\n",
              " ['regression', 'time series'],\n",
              " ['regression', 'time series'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'time series', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'logistic'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['probability', 'hypothesis testing'],\n",
              " ['r', 'machine learning'],\n",
              " ['time series', 'machine learning'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['distributions', 'self study'],\n",
              " ['r', 'classification'],\n",
              " ['r', 'hypothesis testing', 'self study'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['r', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['time series', 'machine learning'],\n",
              " ['machine learning', 'classification'],\n",
              " ['time series', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'time series'],\n",
              " ['distributions', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'time series'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['machine learning', 'self study'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['machine learning', 'classification'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'machine learning'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'distributions'],\n",
              " ['regression', 'time series'],\n",
              " ['regression', 'self study'],\n",
              " ['hypothesis testing', 'distributions'],\n",
              " ['machine learning', 'logistic', 'classification'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'classification'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['regression', 'probability', 'logistic'],\n",
              " ['probability', 'self study'],\n",
              " ['regression', 'self study'],\n",
              " ['regression', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'machine learning', 'classification'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'distributions'],\n",
              " ['probability', 'self study', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'probability', 'classification'],\n",
              " ['time series', 'hypothesis testing'],\n",
              " ['hypothesis testing', 'distributions'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['regression', 'self study'],\n",
              " ['distributions', 'time series'],\n",
              " ['regression', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression', 'probability'],\n",
              " ['r', 'self study'],\n",
              " ['r', 'classification'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['regression', 'time series'],\n",
              " ['distributions', 'probability'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression', 'hypothesis testing'],\n",
              " ['regression', 'self study'],\n",
              " ['regression', 'time series'],\n",
              " ['regression', 'machine learning'],\n",
              " ['distributions', 'time series'],\n",
              " ['regression', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'distributions'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'logistic'],\n",
              " ['machine learning', 'classification'],\n",
              " ['time series', 'probability'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'machine learning'],\n",
              " ['r', 'regression'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['probability', 'distributions'],\n",
              " ['machine learning', 'self study', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'time series', 'machine learning'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'distributions'],\n",
              " ['distributions', 'hypothesis testing'],\n",
              " ['machine learning', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'machine learning'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'distributions'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'logistic'],\n",
              " ['regression', 'time series'],\n",
              " ['probability', 'self study'],\n",
              " ['time series', 'probability'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'machine learning'],\n",
              " ['time series', 'hypothesis testing', 'distributions'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'logistic'],\n",
              " ['time series', 'logistic'],\n",
              " ['r', 'time series', 'hypothesis testing'],\n",
              " ['probability', 'self study'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'time series', 'self study'],\n",
              " ['r', 'machine learning'],\n",
              " ['regression', 'self study'],\n",
              " ['regression', 'self study'],\n",
              " ['r', 'probability'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['regression', 'logistic'],\n",
              " ['machine learning', 'classification'],\n",
              " ['distributions', 'self study'],\n",
              " ['r', 'distributions'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'machine learning'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'time series'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['time series', 'self study'],\n",
              " ['time series', 'probability'],\n",
              " ['regression', 'machine learning'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression', 'probability', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'self study', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'machine learning'],\n",
              " ['r', 'time series'],\n",
              " ['time series', 'self study'],\n",
              " ['r', 'machine learning'],\n",
              " ['regression', 'logistic'],\n",
              " ['distributions', 'self study'],\n",
              " ['r', 'logistic'],\n",
              " ['machine learning', 'classification'],\n",
              " ['probability', 'distributions'],\n",
              " ['probability', 'hypothesis testing'],\n",
              " ['machine learning', 'classification'],\n",
              " ['time series', 'hypothesis testing'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'machine learning', 'time series'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['probability', 'distributions'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'time series'],\n",
              " ['time series', 'machine learning'],\n",
              " ['r', 'regression'],\n",
              " ['distributions', 'probability'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'machine learning'],\n",
              " ['r', 'machine learning', 'classification'],\n",
              " ['r', 'machine learning'],\n",
              " ['probability', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'time series'],\n",
              " ['probability', 'distributions'],\n",
              " ['probability', 'self study'],\n",
              " ['regression', 'time series'],\n",
              " ['regression', 'probability', 'logistic'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'classification'],\n",
              " ['r', 'hypothesis testing', 'self study'],\n",
              " ['r', 'classification', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'time series'],\n",
              " ['distributions', 'probability'],\n",
              " ['probability', 'hypothesis testing', 'self study'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'logistic'],\n",
              " ['probability', 'distributions'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['regression', 'hypothesis testing'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'distributions'],\n",
              " ['machine learning', 'classification'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'self study'],\n",
              " ['distributions', 'regression', 'self study'],\n",
              " ['probability', 'hypothesis testing', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'time series'],\n",
              " ['r', 'logistic'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['time series', 'hypothesis testing'],\n",
              " ['regression', 'machine learning', 'hypothesis testing'],\n",
              " ['self study', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'time series'],\n",
              " ['r', 'self study'],\n",
              " ['r', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['probability', 'logistic', 'self study'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['regression', 'machine learning'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['time series', 'distributions'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'regression', 'logistic', 'classification'],\n",
              " ['probability', 'distributions'],\n",
              " ['probability', 'distributions'],\n",
              " ['regression', 'time series', 'self study'],\n",
              " ['logistic', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['regression', 'time series'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'machine learning'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'logistic'],\n",
              " ['r', 'time series'],\n",
              " ['hypothesis testing', 'regression', 'logistic'],\n",
              " ['time series', 'classification'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'machine learning', 'classification'],\n",
              " ['r', 'regression', 'logistic'],\n",
              " ['probability', 'distributions', 'self study'],\n",
              " ['probability', 'distributions', 'self study'],\n",
              " ['time series', 'probability'],\n",
              " ['r', 'machine learning'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic'],\n",
              " ['regression', 'distributions'],\n",
              " ['regression', 'machine learning'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'classification'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['regression', 'machine learning'],\n",
              " ['regression', 'logistic'],\n",
              " ['machine learning', 'classification'],\n",
              " ['r', 'time series'],\n",
              " ['time series', 'machine learning'],\n",
              " ['machine learning', 'classification'],\n",
              " ['time series', 'self study'],\n",
              " ['time series', 'self study'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['self study', 'distributions'],\n",
              " ['regression', 'logistic'],\n",
              " ['machine learning', 'classification'],\n",
              " ['time series', 'distributions'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'machine learning'],\n",
              " ['r', 'logistic'],\n",
              " ['distributions', 'hypothesis testing'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['time series', 'classification'],\n",
              " ['regression', 'machine learning'],\n",
              " ['r', 'hypothesis testing'],\n",
              " ['r', 'machine learning', 'logistic'],\n",
              " ['probability', 'self study'],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "hFmgSxWp00Gu",
        "outputId": "dadbe0d6-7d05-4634-cdac-2515735197f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['r', 'time series'],\n",
              " ['regression', 'distributions'],\n",
              " ['distributions', 'probability', 'hypothesis testing'],\n",
              " ['hypothesis testing', 'self study'],\n",
              " ['r', 'regression', 'time series'],\n",
              " ['r', 'time series', 'self study'],\n",
              " ['probability', 'hypothesis testing'],\n",
              " ['r', 'regression'],\n",
              " ['r', 'regression'],\n",
              " ['regression', 'logistic']]"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pzCk5T-KR-W5",
        "outputId": "853b5548-f8fd-4847-9918-32079ba1a145"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11106, 10)"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "y = mlb.fit_transform(y)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "eJxESqMJSEKZ",
        "outputId": "8db5b694-b902-4c5f-a9d2-6042587e4ae3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 1])"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "YZHXV-GqSg3s",
        "outputId": "40306456-595d-4c8e-c779-22d2dea9b4e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['classification', 'distributions', 'hypothesis testing',\n",
              "       'logistic', 'machine learning', 'probability', 'r', 'regression',\n",
              "       'self study', 'time series'], dtype=object)"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlb.classes_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkF4pDaJStjg"
      },
      "source": [
        "We can now split the dataset into training set and validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPHeAiS9KvD9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(x, y, test_size=0.2, random_state=0,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4GaDNwtTmPh"
      },
      "source": [
        "# Text Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtrDalDiPXJM"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer\n",
        "x_tokenizer = Tokenizer()\n",
        "\n",
        "x_tokenizer.fit_on_texts(x_tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zl1vZKpwU2P2",
        "outputId": "e8f6cb76-6d3f-4b11-9969-9a2d58fb2ec4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'i': 2,\n",
              " 'to': 3,\n",
              " 'a': 4,\n",
              " 'of': 5,\n",
              " 'is': 6,\n",
              " 'and': 7,\n",
              " 'in': 8,\n",
              " 'l': 9,\n",
              " 'x': 10,\n",
              " 'for': 11,\n",
              " 'that': 12,\n",
              " 'data': 13,\n",
              " 'this': 14,\n",
              " 't': 15,\n",
              " 'have': 16,\n",
              " 'y': 17,\n",
              " 'with': 18,\n",
              " 'model': 19,\n",
              " 'it': 20,\n",
              " 'are': 21,\n",
              " 'be': 22,\n",
              " 'my': 23,\n",
              " 'as': 24,\n",
              " 'on': 25,\n",
              " 'e': 26,\n",
              " 'p': 27,\n",
              " 'if': 28,\n",
              " 'can': 29,\n",
              " 'n': 30,\n",
              " 'but': 31,\n",
              " 'not': 32,\n",
              " 'm': 33,\n",
              " 'or': 34,\n",
              " 'r': 35,\n",
              " 'how': 36,\n",
              " 'regression': 37,\n",
              " 'c': 38,\n",
              " 'am': 39,\n",
              " 's': 40,\n",
              " 'from': 41,\n",
              " 'test': 42,\n",
              " 'what': 43,\n",
              " 'would': 44,\n",
              " 'b': 45,\n",
              " 'so': 46,\n",
              " 'time': 47,\n",
              " 'there': 48,\n",
              " 'using': 49,\n",
              " 'which': 50,\n",
              " 'an': 51,\n",
              " 'do': 52,\n",
              " 'one': 53,\n",
              " 'each': 54,\n",
              " 'value': 55,\n",
              " 'use': 56,\n",
              " 'by': 57,\n",
              " 'some': 58,\n",
              " 'variables': 59,\n",
              " 'like': 60,\n",
              " 'variable': 61,\n",
              " 'we': 62,\n",
              " 'at': 63,\n",
              " 'na': 64,\n",
              " 'any': 65,\n",
              " 'f': 66,\n",
              " 'distribution': 67,\n",
              " 'two': 68,\n",
              " 'values': 69,\n",
              " 'set': 70,\n",
              " 'you': 71,\n",
              " 'all': 72,\n",
              " 'function': 73,\n",
              " 'fit': 74,\n",
              " 'd': 75,\n",
              " 'beta': 76,\n",
              " 'question': 77,\n",
              " 'then': 78,\n",
              " 'mean': 79,\n",
              " 'me': 80,\n",
              " 'know': 81,\n",
              " 'where': 82,\n",
              " 'when': 83,\n",
              " 'should': 84,\n",
              " 'different': 85,\n",
              " 'want': 86,\n",
              " 'series': 87,\n",
              " 'probability': 88,\n",
              " 'error': 89,\n",
              " 'number': 90,\n",
              " 'logistic': 91,\n",
              " 'problem': 92,\n",
              " 'about': 93,\n",
              " 'z': 94,\n",
              " 'here': 95,\n",
              " 'k': 96,\n",
              " 'get': 97,\n",
              " 'was': 98,\n",
              " 'linear': 99,\n",
              " 'other': 100,\n",
              " 'more': 101,\n",
              " 'will': 102,\n",
              " 'sample': 103,\n",
              " 'between': 104,\n",
              " 'also': 105,\n",
              " 'these': 106,\n",
              " 'has': 107,\n",
              " 'example': 108,\n",
              " 'frac': 109,\n",
              " 'way': 110,\n",
              " 'same': 111,\n",
              " 'sum': 112,\n",
              " 'out': 113,\n",
              " 'right': 114,\n",
              " 'only': 115,\n",
              " 'h': 116,\n",
              " 'following': 117,\n",
              " 'could': 118,\n",
              " 'does': 119,\n",
              " 'random': 120,\n",
              " 'than': 121,\n",
              " 'log': 122,\n",
              " 'first': 123,\n",
              " 'given': 124,\n",
              " 'find': 125,\n",
              " 'used': 126,\n",
              " 'however': 127,\n",
              " 'models': 128,\n",
              " 'they': 129,\n",
              " 'no': 130,\n",
              " 'theta': 131,\n",
              " 'class': 132,\n",
              " 'just': 133,\n",
              " 'predict': 134,\n",
              " 'df': 135,\n",
              " 'results': 136,\n",
              " 'q': 137,\n",
              " 'w': 138,\n",
              " 'trying': 139,\n",
              " 'now': 140,\n",
              " 'training': 141,\n",
              " 'coefficients': 142,\n",
              " 'need': 143,\n",
              " 'plot': 144,\n",
              " 'v': 145,\n",
              " 'g': 146,\n",
              " 'method': 147,\n",
              " 'j': 148,\n",
              " 'case': 149,\n",
              " 'dataset': 150,\n",
              " 'very': 151,\n",
              " 'help': 152,\n",
              " 'true': 153,\n",
              " 'lm': 154,\n",
              " 'estimate': 155,\n",
              " 'sigma': 156,\n",
              " 'into': 157,\n",
              " 'see': 158,\n",
              " 'alpha': 159,\n",
              " 'don': 160,\n",
              " 've': 161,\n",
              " 'say': 162,\n",
              " 'matrix': 163,\n",
              " 'package': 164,\n",
              " 'such': 165,\n",
              " 'classification': 166,\n",
              " 'code': 167,\n",
              " 'factor': 168,\n",
              " 'analysis': 169,\n",
              " 'because': 170,\n",
              " 'understand': 171,\n",
              " 'left': 172,\n",
              " 'why': 173,\n",
              " 'hat': 174,\n",
              " 'thanks': 175,\n",
              " 'independent': 176,\n",
              " 'intercept': 177,\n",
              " 'new': 178,\n",
              " 'based': 179,\n",
              " 'type': 180,\n",
              " 'group': 181,\n",
              " 'glm': 182,\n",
              " 'correct': 183,\n",
              " 'best': 184,\n",
              " 'order': 185,\n",
              " 'make': 186,\n",
              " 'let': 187,\n",
              " 'standard': 188,\n",
              " 'u': 189,\n",
              " 'both': 190,\n",
              " 'output': 191,\n",
              " 'mu': 192,\n",
              " 'good': 193,\n",
              " 'possible': 194,\n",
              " 'over': 195,\n",
              " 'arima': 196,\n",
              " 'them': 197,\n",
              " 'text': 198,\n",
              " 'approach': 199,\n",
              " 'binomial': 200,\n",
              " 'age': 201,\n",
              " 'features': 202,\n",
              " 'response': 203,\n",
              " 'year': 204,\n",
              " 'point': 205,\n",
              " 'something': 206,\n",
              " 'significant': 207,\n",
              " 'whether': 208,\n",
              " 'better': 209,\n",
              " 'points': 210,\n",
              " 'up': 211,\n",
              " 'think': 212,\n",
              " 'been': 213,\n",
              " 'parameters': 214,\n",
              " 'residuals': 215,\n",
              " 'observations': 216,\n",
              " 'formula': 217,\n",
              " 'sure': 218,\n",
              " 'calculate': 219,\n",
              " 'train': 220,\n",
              " 'since': 221,\n",
              " 'binary': 222,\n",
              " 'run': 223,\n",
              " 'size': 224,\n",
              " 'summary': 225,\n",
              " 'variance': 226,\n",
              " 'non': 227,\n",
              " 'hypothesis': 228,\n",
              " 'var': 229,\n",
              " 'above': 230,\n",
              " 'below': 231,\n",
              " 'end': 232,\n",
              " 'after': 233,\n",
              " 'length': 234,\n",
              " 'learning': 235,\n",
              " 'normal': 236,\n",
              " 'lambda': 237,\n",
              " 'level': 238,\n",
              " 'result': 239,\n",
              " 'dependent': 240,\n",
              " 'difference': 241,\n",
              " 'family': 242,\n",
              " 'seems': 243,\n",
              " 'tried': 244,\n",
              " 'forecast': 245,\n",
              " 'null': 246,\n",
              " 'times': 247,\n",
              " 'many': 248,\n",
              " 'prediction': 249,\n",
              " 'doing': 250,\n",
              " 'questions': 251,\n",
              " 'much': 252,\n",
              " 'max': 253,\n",
              " 'effect': 254,\n",
              " 'answer': 255,\n",
              " 'looking': 256,\n",
              " 'well': 257,\n",
              " 'pr': 258,\n",
              " 'classifier': 259,\n",
              " 'parameter': 260,\n",
              " 'vector': 261,\n",
              " 'continuous': 262,\n",
              " 'multiple': 263,\n",
              " 'were': 264,\n",
              " 'found': 265,\n",
              " 'please': 266,\n",
              " 'may': 267,\n",
              " 'squared': 268,\n",
              " 'library': 269,\n",
              " 'their': 270,\n",
              " 'samples': 271,\n",
              " 'most': 272,\n",
              " 'simple': 273,\n",
              " 'predictor': 274,\n",
              " 'frame': 275,\n",
              " 'likelihood': 276,\n",
              " 'etc': 277,\n",
              " 'second': 278,\n",
              " 'correlation': 279,\n",
              " 'predictors': 280,\n",
              " 'being': 281,\n",
              " 'give': 282,\n",
              " 'change': 283,\n",
              " 'list': 284,\n",
              " 'score': 285,\n",
              " 'accuracy': 286,\n",
              " 'feature': 287,\n",
              " 'outcome': 288,\n",
              " 'might': 289,\n",
              " 'really': 290,\n",
              " 'its': 291,\n",
              " 'day': 292,\n",
              " 'information': 293,\n",
              " 'even': 294,\n",
              " 'similar': 295,\n",
              " 'means': 296,\n",
              " 'epsilon': 297,\n",
              " 'categorical': 298,\n",
              " 'equation': 299,\n",
              " 'take': 300,\n",
              " 'false': 301,\n",
              " 'min': 302,\n",
              " 'work': 303,\n",
              " 'those': 304,\n",
              " 'input': 305,\n",
              " 'anyone': 306,\n",
              " 'std': 307,\n",
              " 'look': 308,\n",
              " 'another': 309,\n",
              " 'exp': 310,\n",
              " 'suppose': 311,\n",
              " 'zero': 312,\n",
              " 'average': 313,\n",
              " 'read': 314,\n",
              " 'total': 315,\n",
              " 'mathbf': 316,\n",
              " 'before': 317,\n",
              " 'logit': 318,\n",
              " 'terms': 319,\n",
              " 'effects': 320,\n",
              " 'three': 321,\n",
              " 'algorithm': 322,\n",
              " 'compare': 323,\n",
              " 'ts': 324,\n",
              " 'interval': 325,\n",
              " 'gamma': 326,\n",
              " 'still': 327,\n",
              " 'show': 328,\n",
              " 'negative': 329,\n",
              " 'working': 330,\n",
              " 'probabilities': 331,\n",
              " 'high': 332,\n",
              " 'machine': 333,\n",
              " 'table': 334,\n",
              " 'having': 335,\n",
              " 'cross': 336,\n",
              " 'confidence': 337,\n",
              " 'start': 338,\n",
              " 'testing': 339,\n",
              " 'predicted': 340,\n",
              " 'statistical': 341,\n",
              " 'while': 342,\n",
              " 'did': 343,\n",
              " 'your': 344,\n",
              " 'rate': 345,\n",
              " 'levels': 346,\n",
              " 'wrong': 347,\n",
              " 'groups': 348,\n",
              " 'large': 349,\n",
              " 'assume': 350,\n",
              " 'scale': 351,\n",
              " 'coefficient': 352,\n",
              " 'bar': 353,\n",
              " 'line': 354,\n",
              " 'residual': 355,\n",
              " 'statistics': 356,\n",
              " 'days': 357,\n",
              " 'positive': 358,\n",
              " 'call': 359,\n",
              " 'methods': 360,\n",
              " 'distributions': 361,\n",
              " 'phi': 362,\n",
              " 'someone': 363,\n",
              " 'term': 364,\n",
              " 'edit': 365,\n",
              " 'cases': 366,\n",
              " 'every': 367,\n",
              " 'far': 368,\n",
              " 'able': 369,\n",
              " 'process': 370,\n",
              " 'statistic': 371,\n",
              " 'people': 372,\n",
              " 'determine': 373,\n",
              " 'fitted': 374,\n",
              " 'gives': 375,\n",
              " 'step': 376,\n",
              " 'validation': 377,\n",
              " 'lag': 378,\n",
              " 'deviance': 379,\n",
              " 'appreciated': 380,\n",
              " 'part': 381,\n",
              " 'sqrt': 382,\n",
              " 'ratio': 383,\n",
              " 'thank': 384,\n",
              " 'form': 385,\n",
              " 'tests': 386,\n",
              " 'classes': 387,\n",
              " 'without': 388,\n",
              " 'degrees': 389,\n",
              " 'freedom': 390,\n",
              " 'idea': 391,\n",
              " 'try': 392,\n",
              " 'rep': 393,\n",
              " 'aic': 394,\n",
              " 'within': 395,\n",
              " 'least': 396,\n",
              " 'measure': 397,\n",
              " 'around': 398,\n",
              " 'got': 399,\n",
              " 'perform': 400,\n",
              " 'sim': 401,\n",
              " 'done': 402,\n",
              " 'per': 403,\n",
              " 'doesn': 404,\n",
              " 'had': 405,\n",
              " 'create': 406,\n",
              " 'sense': 407,\n",
              " 'link': 408,\n",
              " 'real': 409,\n",
              " 'rnorm': 410,\n",
              " 'interaction': 411,\n",
              " 'price': 412,\n",
              " 'median': 413,\n",
              " 'explain': 414,\n",
              " 'trend': 415,\n",
              " 'month': 416,\n",
              " 'vs': 417,\n",
              " 'follows': 418,\n",
              " 'specific': 419,\n",
              " 'chi': 420,\n",
              " 'years': 421,\n",
              " 'weight': 422,\n",
              " 'yes': 423,\n",
              " 'begin': 424,\n",
              " 'population': 425,\n",
              " 'looks': 426,\n",
              " 'particular': 427,\n",
              " 'id': 428,\n",
              " 'kind': 429,\n",
              " 'state': 430,\n",
              " 'missing': 431,\n",
              " 'event': 432,\n",
              " 'control': 433,\n",
              " 'less': 434,\n",
              " 'go': 435,\n",
              " 'expected': 436,\n",
              " 'equal': 437,\n",
              " 'small': 438,\n",
              " 'sd': 439,\n",
              " 'wondering': 440,\n",
              " 'compute': 441,\n",
              " 'performance': 442,\n",
              " 'errors': 443,\n",
              " 'too': 444,\n",
              " 'actually': 445,\n",
              " 'single': 446,\n",
              " 'distributed': 447,\n",
              " 'several': 448,\n",
              " 'apply': 449,\n",
              " 'svm': 450,\n",
              " 'seem': 451,\n",
              " 'treatment': 452,\n",
              " 'observation': 453,\n",
              " 'estimates': 454,\n",
              " 'weights': 455,\n",
              " 'either': 456,\n",
              " 'consider': 457,\n",
              " 'frequency': 458,\n",
              " 'density': 459,\n",
              " 'instead': 460,\n",
              " 'cannot': 461,\n",
              " 'thought': 462,\n",
              " 'check': 463,\n",
              " 'int': 464,\n",
              " 'sets': 465,\n",
              " 'estimated': 466,\n",
              " 'solution': 467,\n",
              " 'interested': 468,\n",
              " 'certain': 469,\n",
              " 'range': 470,\n",
              " 'general': 471,\n",
              " 'power': 472,\n",
              " 'date': 473,\n",
              " 'sales': 474,\n",
              " 'low': 475,\n",
              " 'quite': 476,\n",
              " 'appropriate': 477,\n",
              " 'choose': 478,\n",
              " 'solve': 479,\n",
              " 'poisson': 480,\n",
              " 'our': 481,\n",
              " 'through': 482,\n",
              " 'col': 483,\n",
              " 'few': 484,\n",
              " 'odds': 485,\n",
              " 'anova': 486,\n",
              " 'pi': 487,\n",
              " 'next': 488,\n",
              " 'dummy': 489,\n",
              " 'numeric': 490,\n",
              " 'period': 491,\n",
              " 'http': 492,\n",
              " 'individual': 493,\n",
              " 'fixed': 494,\n",
              " 'last': 495,\n",
              " 'figure': 496,\n",
              " 'factors': 497,\n",
              " 'add': 498,\n",
              " 'original': 499,\n",
              " 'build': 500,\n",
              " 'subject': 501,\n",
              " 'pred': 502,\n",
              " 'significance': 503,\n",
              " 'mod': 504,\n",
              " 'getting': 505,\n",
              " 'higher': 506,\n",
              " 'fitting': 507,\n",
              " 'include': 508,\n",
              " 'note': 509,\n",
              " 'across': 510,\n",
              " 'delta': 511,\n",
              " 'running': 512,\n",
              " 'calculated': 513,\n",
              " 'examples': 514,\n",
              " 'predictions': 515,\n",
              " 'ar': 516,\n",
              " 'paper': 517,\n",
              " 'lower': 518,\n",
              " 'advance': 519,\n",
              " 'actual': 520,\n",
              " 'relationship': 521,\n",
              " 'return': 522,\n",
              " 'count': 523,\n",
              " 'structure': 524,\n",
              " 'lot': 525,\n",
              " 'who': 526,\n",
              " 'infty': 527,\n",
              " 'functions': 528,\n",
              " 'red': 529,\n",
              " 'related': 530,\n",
              " 'product': 531,\n",
              " 'observed': 532,\n",
              " 'selection': 533,\n",
              " 'interpret': 534,\n",
              " 'codes': 535,\n",
              " 'dat': 536,\n",
              " 'generate': 537,\n",
              " 'under': 538,\n",
              " 'though': 539,\n",
              " 'currently': 540,\n",
              " 'category': 541,\n",
              " 'square': 542,\n",
              " 'label': 543,\n",
              " 'rather': 544,\n",
              " 'understanding': 545,\n",
              " 'numbers': 546,\n",
              " 'cost': 547,\n",
              " 'course': 548,\n",
              " 'target': 549,\n",
              " 'made': 550,\n",
              " 'distance': 551,\n",
              " 'exactly': 552,\n",
              " 'space': 553,\n",
              " 'previous': 554,\n",
              " 'coef': 555,\n",
              " 'constant': 556,\n",
              " 'main': 557,\n",
              " 'thinking': 558,\n",
              " 'curve': 559,\n",
              " 'problems': 560,\n",
              " 'scores': 561,\n",
              " 'bit': 562,\n",
              " 'gaussian': 563,\n",
              " 'thus': 564,\n",
              " 'mathbb': 565,\n",
              " 'simply': 566,\n",
              " 'prior': 567,\n",
              " 'always': 568,\n",
              " 'therefore': 569,\n",
              " 'final': 570,\n",
              " 'alternative': 571,\n",
              " 'going': 572,\n",
              " 'likely': 573,\n",
              " 'network': 574,\n",
              " 'maybe': 575,\n",
              " 'tree': 576,\n",
              " 'book': 577,\n",
              " 'lines': 578,\n",
              " 'sex': 579,\n",
              " 'leq': 580,\n",
              " 'object': 581,\n",
              " 'seasonal': 582,\n",
              " 'study': 583,\n",
              " 'row': 584,\n",
              " 'long': 585,\n",
              " 'big': 586,\n",
              " 'auto': 587,\n",
              " 'known': 588,\n",
              " 'fact': 589,\n",
              " 'slope': 590,\n",
              " 'column': 591,\n",
              " 'account': 592,\n",
              " 'come': 593,\n",
              " 'user': 594,\n",
              " 'signif': 595,\n",
              " 'important': 596,\n",
              " 'differences': 597,\n",
              " 'rows': 598,\n",
              " 'events': 599,\n",
              " 'due': 600,\n",
              " 'words': 601,\n",
              " 'neural': 602,\n",
              " 'daily': 603,\n",
              " 'se': 604,\n",
              " 'names': 605,\n",
              " 'post': 606,\n",
              " 'full': 607,\n",
              " 'procedure': 608,\n",
              " 'tell': 609,\n",
              " 'already': 610,\n",
              " 'mydata': 611,\n",
              " 'adjusted': 612,\n",
              " 'gender': 613,\n",
              " 'forest': 614,\n",
              " 'makes': 615,\n",
              " 're': 616,\n",
              " 'seed': 617,\n",
              " 'decision': 618,\n",
              " 'appreciate': 619,\n",
              " 'he': 620,\n",
              " 'pdf': 621,\n",
              " 'maximum': 622,\n",
              " 'index': 623,\n",
              " 'print': 624,\n",
              " 'current': 625,\n",
              " 'algorithms': 626,\n",
              " 'deviation': 627,\n",
              " 'shape': 628,\n",
              " 'reading': 629,\n",
              " 'issue': 630,\n",
              " 'system': 631,\n",
              " 'seasonality': 632,\n",
              " 'provide': 633,\n",
              " 'reason': 634,\n",
              " 'increase': 635,\n",
              " 'enough': 636,\n",
              " 'ols': 637,\n",
              " 'again': 638,\n",
              " 'intervals': 639,\n",
              " 'shows': 640,\n",
              " 'confused': 641,\n",
              " 'amount': 642,\n",
              " 'csv': 643,\n",
              " 'conditional': 644,\n",
              " 'cdot': 645,\n",
              " 'proportion': 646,\n",
              " 'com': 647,\n",
              " 'labels': 648,\n",
              " 'guess': 649,\n",
              " 'taken': 650,\n",
              " 'significantly': 651,\n",
              " 'graph': 652,\n",
              " 'taking': 653,\n",
              " 'diff': 654,\n",
              " 'rank': 655,\n",
              " 'learn': 656,\n",
              " 'according': 657,\n",
              " 'stationary': 658,\n",
              " 'acf': 659,\n",
              " 'page': 660,\n",
              " 'noise': 661,\n",
              " 'categories': 662,\n",
              " 'obtain': 663,\n",
              " 'update': 664,\n",
              " 'datasets': 665,\n",
              " 'success': 666,\n",
              " 'correctly': 667,\n",
              " 'person': 668,\n",
              " 'down': 669,\n",
              " 'against': 670,\n",
              " 'bad': 671,\n",
              " 'classify': 672,\n",
              " 'must': 673,\n",
              " 'threshold': 674,\n",
              " 'sampling': 675,\n",
              " 'instance': 676,\n",
              " 'assumption': 677,\n",
              " 'close': 678,\n",
              " 'suggestions': 679,\n",
              " 'columns': 680,\n",
              " 'student': 681,\n",
              " 'defined': 682,\n",
              " 'cbind': 683,\n",
              " 'partial': 684,\n",
              " 'condition': 685,\n",
              " 'name': 686,\n",
              " 'temperature': 687,\n",
              " 'greater': 688,\n",
              " 'else': 689,\n",
              " 'things': 690,\n",
              " 'anything': 691,\n",
              " 'loss': 692,\n",
              " 'seen': 693,\n",
              " 'believe': 694,\n",
              " 'little': 695,\n",
              " 'blue': 696,\n",
              " 'assuming': 697,\n",
              " 'male': 698,\n",
              " 'correlated': 699,\n",
              " 'statistically': 700,\n",
              " 'suggest': 701,\n",
              " 'direction': 702,\n",
              " 'support': 703,\n",
              " 'experiment': 704,\n",
              " 'goal': 705,\n",
              " 'area': 706,\n",
              " 'predictive': 707,\n",
              " 'week': 708,\n",
              " 'vectors': 709,\n",
              " 'basic': 710,\n",
              " 'cv': 711,\n",
              " 'classifiers': 712,\n",
              " 'available': 713,\n",
              " 'iv': 714,\n",
              " 'region': 715,\n",
              " 'subset': 716,\n",
              " 'ldots': 717,\n",
              " 'explanatory': 718,\n",
              " 'discrete': 719,\n",
              " 'off': 720,\n",
              " 'chance': 721,\n",
              " 'select': 722,\n",
              " 'reference': 723,\n",
              " 'split': 724,\n",
              " 'works': 725,\n",
              " 'us': 726,\n",
              " 'ones': 727,\n",
              " 'ways': 728,\n",
              " 'shown': 729,\n",
              " 'task': 730,\n",
              " 'transformation': 731,\n",
              " 'clear': 732,\n",
              " 'seq': 733,\n",
              " 'multivariate': 734,\n",
              " 'obtained': 735,\n",
              " 'trees': 736,\n",
              " 'rm': 737,\n",
              " 'unit': 738,\n",
              " 'thing': 739,\n",
              " 'during': 740,\n",
              " 'estimation': 741,\n",
              " 'ab': 742,\n",
              " 'contains': 743,\n",
              " 'basically': 744,\n",
              " 'st': 745,\n",
              " 'align': 746,\n",
              " 'months': 747,\n",
              " 'normally': 748,\n",
              " 'follow': 749,\n",
              " 'future': 750,\n",
              " 'array': 751,\n",
              " 'female': 752,\n",
              " 'advice': 753,\n",
              " 'mathcal': 754,\n",
              " 'measures': 755,\n",
              " 'roc': 756,\n",
              " 'vec': 757,\n",
              " 'income': 758,\n",
              " 'others': 759,\n",
              " 'isn': 760,\n",
              " 'forecasting': 761,\n",
              " 'default': 762,\n",
              " 'packages': 763,\n",
              " 'further': 764,\n",
              " 'pattern': 765,\n",
              " 'returns': 766,\n",
              " 'changes': 767,\n",
              " 'covariates': 768,\n",
              " 'write': 769,\n",
              " 'asked': 770,\n",
              " 'squares': 771,\n",
              " 'randomly': 772,\n",
              " 'bayes': 773,\n",
              " 'prob': 774,\n",
              " 'temp': 775,\n",
              " 'finding': 776,\n",
              " 'overall': 777,\n",
              " 'corresponding': 778,\n",
              " 'initial': 779,\n",
              " 'multinomial': 780,\n",
              " 'bayesian': 781,\n",
              " 'res': 782,\n",
              " 'exponential': 783,\n",
              " 'useful': 784,\n",
              " 'iterations': 785,\n",
              " 'ran': 786,\n",
              " 'measured': 787,\n",
              " 'four': 788,\n",
              " 'stats': 789,\n",
              " 'predicting': 790,\n",
              " 'exact': 791,\n",
              " 'generated': 792,\n",
              " 'situation': 793,\n",
              " 'sort': 794,\n",
              " 'monthly': 795,\n",
              " 'pretty': 796,\n",
              " 'probably': 797,\n",
              " 'll': 798,\n",
              " 'students': 799,\n",
              " 'research': 800,\n",
              " 'including': 801,\n",
              " 'naive': 802,\n",
              " 'rho': 803,\n",
              " 'represent': 804,\n",
              " 'glmnet': 805,\n",
              " 'plots': 806,\n",
              " 'sequence': 807,\n",
              " 'image': 808,\n",
              " 'measurements': 809,\n",
              " 'once': 810,\n",
              " 'put': 811,\n",
              " 'ln': 812,\n",
              " 'cluster': 813,\n",
              " 'uses': 814,\n",
              " 'ml': 815,\n",
              " 'th': 816,\n",
              " 'implement': 817,\n",
              " 'past': 818,\n",
              " 'mixed': 819,\n",
              " 'types': 820,\n",
              " 'ordinal': 821,\n",
              " 'compared': 822,\n",
              " 'hidden': 823,\n",
              " 'season': 824,\n",
              " 'combination': 825,\n",
              " 'covariance': 826,\n",
              " 'ask': 827,\n",
              " 'although': 828,\n",
              " 'uniform': 829,\n",
              " 'steps': 830,\n",
              " 'risk': 831,\n",
              " 'np': 832,\n",
              " 'answers': 833,\n",
              " 'cov': 834,\n",
              " 'says': 835,\n",
              " 'applied': 836,\n",
              " 'project': 837,\n",
              " 'created': 838,\n",
              " 'choice': 839,\n",
              " 'relative': 840,\n",
              " 'hand': 841,\n",
              " 'raw': 842,\n",
              " 'valid': 843,\n",
              " 'head': 844,\n",
              " 'species': 845,\n",
              " 'gradient': 846,\n",
              " 'called': 847,\n",
              " 'num': 848,\n",
              " 'whole': 849,\n",
              " 'easy': 850,\n",
              " 'associated': 851,\n",
              " 'selected': 852,\n",
              " 'larger': 853,\n",
              " 'perhaps': 854,\n",
              " 'match': 855,\n",
              " 'site': 856,\n",
              " 'dots': 857,\n",
              " 'tau': 858,\n",
              " 'o': 859,\n",
              " 'obs': 860,\n",
              " 'among': 861,\n",
              " 'techniques': 862,\n",
              " 'expect': 863,\n",
              " 'nrow': 864,\n",
              " 'back': 865,\n",
              " 'top': 866,\n",
              " 'transform': 867,\n",
              " 'common': 868,\n",
              " 'comes': 869,\n",
              " 'file': 870,\n",
              " 'omega': 871,\n",
              " 'dv': 872,\n",
              " 'adding': 873,\n",
              " 'regarding': 874,\n",
              " 'auc': 875,\n",
              " 'wanted': 876,\n",
              " 'optimal': 877,\n",
              " 'scaled': 878,\n",
              " 'survival': 879,\n",
              " 'comparing': 880,\n",
              " 'modeling': 881,\n",
              " 'regressions': 882,\n",
              " 'define': 883,\n",
              " 'quad': 884,\n",
              " 'knowledge': 885,\n",
              " 'building': 886,\n",
              " 'importance': 887,\n",
              " 'context': 888,\n",
              " 'fold': 889,\n",
              " 'approaches': 890,\n",
              " 'game': 891,\n",
              " 'weighted': 892,\n",
              " 'outliers': 893,\n",
              " 'reject': 894,\n",
              " 'obviously': 895,\n",
              " 'hope': 896,\n",
              " 'various': 897,\n",
              " 'status': 898,\n",
              " 'present': 899,\n",
              " 'additional': 900,\n",
              " 'customer': 901,\n",
              " 'estimator': 902,\n",
              " 'background': 903,\n",
              " 'takes': 904,\n",
              " 'added': 905,\n",
              " 'specifically': 906,\n",
              " 'www': 907,\n",
              " 'box': 908,\n",
              " 'own': 909,\n",
              " 'individuals': 910,\n",
              " 'otherwise': 911,\n",
              " 'component': 912,\n",
              " 'keep': 913,\n",
              " 'self': 914,\n",
              " 'assumptions': 915,\n",
              " 'interest': 916,\n",
              " 'ma': 917,\n",
              " 'components': 918,\n",
              " 'subjects': 919,\n",
              " 'require': 920,\n",
              " 'attributes': 921,\n",
              " 'highly': 922,\n",
              " 'suggested': 923,\n",
              " 'root': 924,\n",
              " 'greatly': 925,\n",
              " 'interpretation': 926,\n",
              " 'axis': 927,\n",
              " 'states': 928,\n",
              " 'included': 929,\n",
              " 'often': 930,\n",
              " 'implementation': 931,\n",
              " 'hence': 932,\n",
              " 'remove': 933,\n",
              " 'option': 934,\n",
              " 'patients': 935,\n",
              " 'separate': 936,\n",
              " 'fisher': 937,\n",
              " 'python': 938,\n",
              " 'theory': 939,\n",
              " 'considered': 940,\n",
              " 'explanation': 941,\n",
              " 'white': 942,\n",
              " 'identify': 943,\n",
              " 'trained': 944,\n",
              " 'window': 945,\n",
              " 'location': 946,\n",
              " 'almost': 947,\n",
              " 'kernel': 948,\n",
              " 'prices': 949,\n",
              " 'simulation': 950,\n",
              " 'unknown': 951,\n",
              " 'inputs': 952,\n",
              " 'great': 953,\n",
              " 'polynomial': 954,\n",
              " 'qu': 955,\n",
              " 'deal': 956,\n",
              " 'percentage': 957,\n",
              " 'autocorrelation': 958,\n",
              " 'balls': 959,\n",
              " 'overline': 960,\n",
              " 'outputs': 961,\n",
              " 'bootstrap': 962,\n",
              " 'improve': 963,\n",
              " 'wt': 964,\n",
              " 'none': 965,\n",
              " 'bias': 966,\n",
              " 'calculating': 967,\n",
              " 'reasonable': 968,\n",
              " 'limits': 969,\n",
              " 'evaluate': 970,\n",
              " 'usually': 971,\n",
              " 'posterior': 972,\n",
              " 'came': 973,\n",
              " 'upper': 974,\n",
              " 'pca': 975,\n",
              " 'relevant': 976,\n",
              " 'ideas': 977,\n",
              " 'fits': 978,\n",
              " 'users': 979,\n",
              " 'together': 980,\n",
              " 'items': 981,\n",
              " 'ci': 982,\n",
              " 'outcomes': 983,\n",
              " 'prove': 984,\n",
              " 'runif': 985,\n",
              " 'along': 986,\n",
              " 'unfortunately': 987,\n",
              " 'hour': 988,\n",
              " 'trials': 989,\n",
              " 'conditions': 990,\n",
              " 'randomforest': 991,\n",
              " 'message': 992,\n",
              " 'making': 993,\n",
              " 'lasso': 994,\n",
              " 'sub': 995,\n",
              " 'stat': 996,\n",
              " 'feel': 997,\n",
              " 'command': 998,\n",
              " 'le': 999,\n",
              " 'instances': 1000,\n",
              " ...}"
            ]
          },
          "execution_count": 33,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Srz9RWKvVsm7",
        "outputId": "6531970c-4625-4588-cb5c-d58001591cc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25312"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQLwSve9VYqN"
      },
      "source": [
        "There are around 25,000 tokens in the training dataset. Let's see how many tokens appear at least 5 times in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "H-d_UjVmPjgo",
        "outputId": "265343d4-8a97-448c-b198-01c4851304ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12574\n"
          ]
        }
      ],
      "source": [
        "thresh = 3\n",
        "\n",
        "cnt=0\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "  if value>=thresh:\n",
        "    cnt=cnt+1\n",
        "\n",
        "print(cnt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Eqly3dnVh-S"
      },
      "source": [
        "Over 12,000 tokens have appeared three times or more in the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZrJnr-dItPn"
      },
      "outputs": [],
      "source": [
        "# prepare the tokenizer again\n",
        "x_tokenizer = Tokenizer(num_words=cnt,oov_token='unk')\n",
        "\n",
        "#prepare vocabulary\n",
        "x_tokenizer.fit_on_texts(x_tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJFfvLDJWZbb"
      },
      "source": [
        "Now that we have encoded every token to an integer, let's convert the text sequences to integer sequences. After that we will pad the integer sequences to the maximum sequence length, i.e., 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpJvPYx5WR07"
      },
      "outputs": [],
      "source": [
        "# maximum sequence length allowed\n",
        "max_len = 100\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq = x_tokenizer.texts_to_sequences(x_tr)\n",
        "x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding up with zero\n",
        "x_tr_seq = pad_sequences(x_tr_seq,  padding='post', maxlen=max_len)\n",
        "x_val_seq = pad_sequences(x_val_seq, padding='post', maxlen=max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TkeQpLgXled"
      },
      "source": [
        "Since we are padding the sequences with zeros, we must increment the vocabulary size by one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Q4na29hBItes",
        "outputId": "b7024c4f-0135-4381-f3b0-ff9aa8f85c52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12575"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#no. of unique words\n",
        "x_voc_size = x_tokenizer.num_words + 1\n",
        "x_voc_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "A9jdhRc_O12J",
        "outputId": "069d5743-397b-4466-d223-be09d9cb79ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1953, 5711,  416, 2023,    1,  226, 1747, 3740,  609,   43,  181,\n",
              "       1953,  372,   19,  100,  416,    9, 1747, 3839,  238,   27,   27,\n",
              "         27,   27,   27,   70,    6, 6919,    8, 1163,   70,    6,   43,\n",
              "         43, 1802, 1802, 1802,   36,   36,   36,   36, 4308, 5410,    4,\n",
              "        124,  592,  107,   22,    2, 1747, 4065,   27,   10, 1309,   10,\n",
              "       6414,   10,  190,   10,  416,   10,   27,   10, 1309,   10, 6414,\n",
              "         10,  190,   10,  416,   10,  456,  139,   15,    7,    2, 4610,\n",
              "        164,   27,   10, 1309,   10, 6414,   10,  190,   10,  416,   10,\n",
              "         27,   76,   27, 1309,   76,   27, 6414,   76,   27,  190,   76,\n",
              "         27], dtype=int32)"
            ]
          },
          "execution_count": 39,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_tr_seq[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCtPnSrsscN1"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrRgqQ4M8OZu"
      },
      "outputs": [],
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.callbacks import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxE6IK3Uic-d"
      },
      "source": [
        "### Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHtamwcMkVcr"
      },
      "outputs": [],
      "source": [
        "#sequential model\n",
        "model = Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(x_voc_size, 50, input_shape=(max_len,), mask_zero=True))\n",
        "\n",
        "#rnn layer\n",
        "model.add(SimpleRNN(128,activation='relu'))\n",
        "\n",
        "#dense layer\n",
        "model.add(Dense(128,activation='relu'))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(10,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wd26r0y3n4c"
      },
      "source": [
        "Understand the output shape and no. of parameters of each layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "6K14UgT--fCk",
        "outputId": "dbce82a2-d8ae-4dd8-87e8-620c9b3302f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 50)           628750    \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 128)               22912     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 669,464\n",
            "Trainable params: 669,464\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGk0ELGi3yjx"
      },
      "source": [
        "Define the optimizer and loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzRoTFVIItjK"
      },
      "outputs": [],
      "source": [
        "#define optimizer and loss\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4w6YHUD4BC1"
      },
      "source": [
        "Define a callback - Model Checkpoint. Model Checkpoint is a callback used to save the best model during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpomosTF4AKW"
      },
      "outputs": [],
      "source": [
        "# checkpoint to save best model during training\n",
        "mc = ModelCheckpoint(\"weights.best.hdf5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80gtKbElii0e"
      },
      "source": [
        "### Train the Model\n",
        "\n",
        "Lets train the model for 10 epochs with a batch size of 128:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "XH8ggzcdkzkL",
        "outputId": "5039337d-0498-46cd-ad86-5bb7a41c8444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 8884 samples, validate on 2222 samples\n",
            "Epoch 1/10\n",
            "8884/8884 [==============================] - 7s 792us/step - loss: 0.5166 - val_loss: 0.4769\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.47690, saving model to weights.best.hdf5\n",
            "Epoch 2/10\n",
            "8884/8884 [==============================] - 7s 744us/step - loss: 0.4648 - val_loss: 0.4564\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.47690 to 0.45641, saving model to weights.best.hdf5\n",
            "Epoch 3/10\n",
            "8884/8884 [==============================] - 7s 751us/step - loss: 0.4194 - val_loss: 0.4252\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.45641 to 0.42519, saving model to weights.best.hdf5\n",
            "Epoch 4/10\n",
            "8884/8884 [==============================] - 7s 746us/step - loss: 0.3931 - val_loss: 0.4107\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.42519 to 0.41074, saving model to weights.best.hdf5\n",
            "Epoch 5/10\n",
            "8884/8884 [==============================] - 7s 742us/step - loss: 0.3595 - val_loss: 0.3988\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.41074 to 0.39884, saving model to weights.best.hdf5\n",
            "Epoch 6/10\n",
            "8884/8884 [==============================] - 7s 735us/step - loss: 0.3343 - val_loss: 0.4009\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.39884\n",
            "Epoch 7/10\n",
            "8884/8884 [==============================] - 7s 739us/step - loss: 0.3145 - val_loss: 0.3996\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.39884\n",
            "Epoch 8/10\n",
            "8884/8884 [==============================] - 7s 734us/step - loss: 0.2899 - val_loss: 0.4074\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.39884\n",
            "Epoch 9/10\n",
            "8884/8884 [==============================] - 7s 753us/step - loss: 0.2635 - val_loss: 0.4103\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.39884\n",
            "Epoch 10/10\n",
            "8884/8884 [==============================] - 7s 752us/step - loss: 0.2506 - val_loss: 0.4366\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.39884\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f96e9343208>"
            ]
          },
          "execution_count": 116,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#train the model\n",
        "model.fit(x_tr_seq, y_tr, batch_size=128, epochs=10, verbose=1, validation_data=(x_val_seq, y_val), callbacks=[mc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDzen8xvioUd"
      },
      "source": [
        "# Model Predictions\n",
        "\n",
        "Load the best model weights and now, the model is ready for the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL8qz8zvDvpH"
      },
      "outputs": [],
      "source": [
        "# load weights into new model\n",
        "model.load_weights(\"weights.best.hdf5\")\n",
        "\n",
        "#predict probabilities\n",
        "pred_prob = model.predict(x_val_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "AUF5H7bIlRLr",
        "outputId": "2e1ef0f8-8c85-4f93-c264-daaaab279980"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.05661559, 0.01500756, 0.0809429 , 0.34682304, 0.14759117,\n",
              "       0.00561154, 0.4962414 , 0.627706  , 0.0462845 , 0.24911207],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 118,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_prob[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph2xAWbFjLv5"
      },
      "source": [
        "The predictions are in terms of probabilities for each of the 10 tags. Hence we need to have a threshold value to convert these probabilities to 0 or 1.\n",
        "\n",
        "Let's specify a set of candidate threshold values. We will select the threshold value that performs the best for the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "5hYDCTKXguMF",
        "outputId": "dc4d6021-e020-41d4-9430-a03af2a0abc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
              "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
              "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
              "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
              "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49])"
            ]
          },
          "execution_count": 119,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#define candidate threshold values\n",
        "threshold  = np.arange(0,0.5,0.01)\n",
        "threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA6wMIewkICl"
      },
      "source": [
        "Let's define a function that takes a threshold value and uses it to convert probabilities into 1 or 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aay56TvDGPoX"
      },
      "outputs": [],
      "source": [
        "# convert probabilities into classes or tags based on a threshold value\n",
        "def classify(pred_prob,thresh):\n",
        "  y_pred_seq = []\n",
        "\n",
        "  for i in pred_prob:\n",
        "    temp=[]\n",
        "    for j in i:\n",
        "      if j>=thresh:\n",
        "        temp.append(1)\n",
        "      else:\n",
        "        temp.append(0)\n",
        "    y_pred_seq.append(temp)\n",
        "\n",
        "  return y_pred_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0auJJmNDtv9"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "score=[]\n",
        "\n",
        "#convert to 1 array\n",
        "y_true = np.array(y_val).ravel()\n",
        "\n",
        "for thresh in threshold:\n",
        "\n",
        "    #classes for each threshold\n",
        "    y_pred_seq = classify(pred_prob,thresh)\n",
        "\n",
        "    #convert to 1d array\n",
        "    y_pred = np.array(y_pred_seq).ravel()\n",
        "\n",
        "    score.append(metrics.f1_score(y_true,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jrA8nJIGVBsl",
        "outputId": "0300e7ef-c035-40e8-874e-138c5aab1c59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.29"
            ]
          },
          "execution_count": 122,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the optimal threshold\n",
        "opt = threshold[score.index(max(score))]\n",
        "opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF1mHdE3rjVu"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_74ujVjmVlcT"
      },
      "outputs": [],
      "source": [
        "#predictions for optimal threshold\n",
        "y_pred_seq = classify(pred_prob,opt)\n",
        "y_pred = np.array(y_pred_seq).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "9LKB6W7tItUm",
        "outputId": "5ea69e5f-c08e-4921-9cbf-98665470ac1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.81      0.85     17520\n",
            "           1       0.49      0.67      0.56      4700\n",
            "\n",
            "    accuracy                           0.78     22220\n",
            "   macro avg       0.69      0.74      0.71     22220\n",
            "weighted avg       0.81      0.78      0.79     22220\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(metrics.classification_report(y_true,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzQsUoEV7ldm"
      },
      "outputs": [],
      "source": [
        "y_pred = mlb.inverse_transform(np.array(y_pred_seq))\n",
        "y_true = mlb.inverse_transform(np.array(y_val))\n",
        "\n",
        "df = pd.DataFrame({'comment':x_val,'actual':y_true,'predictions':y_pred})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "plf_uclDlxwL",
        "outputId": "d0e4cf96-8eda-4301-897f-3fb614235f4f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>actual</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1523</th>\n",
              "      <td>i have a really basic understanding of how the package limma works in that it fits a linear model to each row sample in a micro array dataset what i do not understand is how to use a design matrix...</td>\n",
              "      <td>(machine learning, r)</td>\n",
              "      <td>(logistic, r, regression)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1846</th>\n",
              "      <td>i would like to have an lm prediction per country as a new column for df based on the models per each country that should be based on data frame df df read table text target birds wolfs country a ...</td>\n",
              "      <td>(r, regression)</td>\n",
              "      <td>(r, regression, time series)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>i am trying to figure out the inner workings of the mob function in the party package i can t figure out how the splitting variable is selected when it is a categorical variable in the publication...</td>\n",
              "      <td>(machine learning, regression)</td>\n",
              "      <td>(logistic, r, regression)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>771</th>\n",
              "      <td>what is the best method to determine the minimum number of training samples required for a classifier i am only comparing one classifier four class problem discriminant function analysis dfa with ...</td>\n",
              "      <td>(classification, machine learning)</td>\n",
              "      <td>(classification, machine learning)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2190</th>\n",
              "      <td>if this is a duplicate question please point to the right way but the similar questions i ve found here haven t been sufficiently similar suppose i estimate the model y alpha beta x u and find tha...</td>\n",
              "      <td>(hypothesis testing, r, regression)</td>\n",
              "      <td>(r, regression, time series)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>i am trying to fit and forecast log returns of a price data using arima model in r for reproducibility data is provided here steps followed code and results obtained check for outliers package for...</td>\n",
              "      <td>(r, time series)</td>\n",
              "      <td>(r, regression, time series)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>i am trying fit an arima model to stock returns i have reached a decent model using the aic criterion however the ljung box p value under a diagnostic plots are pretty weird the null hypothesis ge...</td>\n",
              "      <td>(r, time series)</td>\n",
              "      <td>(r, regression, time series)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>if there are few predictors that are highly skewed among a larger set of predictors in case of a linear regression problem should a boxcox transformation be applied to only these few predictors or...</td>\n",
              "      <td>(machine learning, regression)</td>\n",
              "      <td>(logistic, machine learning, r, regression)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>i am currently working at work on a project that attempts to predict an environmental change variable i am personally not a huge fan of the project but i still want to do the best job possible any...</td>\n",
              "      <td>(machine learning, r)</td>\n",
              "      <td>(logistic, r, regression, time series)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>i measured one response variable y as a function of two measured independent variables x and x it is common practice in my field of research to transform y into another response variable y x y the...</td>\n",
              "      <td>(r, regression)</td>\n",
              "      <td>(logistic, r, regression, time series)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                      comment  ...                                  predictions\n",
              "1523  i have a really basic understanding of how the package limma works in that it fits a linear model to each row sample in a micro array dataset what i do not understand is how to use a design matrix...  ...                    (logistic, r, regression)\n",
              "1846  i would like to have an lm prediction per country as a new column for df based on the models per each country that should be based on data frame df df read table text target birds wolfs country a ...  ...                 (r, regression, time series)\n",
              "763   i am trying to figure out the inner workings of the mob function in the party package i can t figure out how the splitting variable is selected when it is a categorical variable in the publication...  ...                    (logistic, r, regression)\n",
              "771   what is the best method to determine the minimum number of training samples required for a classifier i am only comparing one classifier four class problem discriminant function analysis dfa with ...  ...           (classification, machine learning)\n",
              "2190  if this is a duplicate question please point to the right way but the similar questions i ve found here haven t been sufficiently similar suppose i estimate the model y alpha beta x u and find tha...  ...                 (r, regression, time series)\n",
              "490   i am trying to fit and forecast log returns of a price data using arima model in r for reproducibility data is provided here steps followed code and results obtained check for outliers package for...  ...                 (r, regression, time series)\n",
              "473   i am trying fit an arima model to stock returns i have reached a decent model using the aic criterion however the ljung box p value under a diagnostic plots are pretty weird the null hypothesis ge...  ...                 (r, regression, time series)\n",
              "689   if there are few predictors that are highly skewed among a larger set of predictors in case of a linear regression problem should a boxcox transformation be applied to only these few predictors or...  ...  (logistic, machine learning, r, regression)\n",
              "767   i am currently working at work on a project that attempts to predict an environmental change variable i am personally not a huge fan of the project but i still want to do the best job possible any...  ...       (logistic, r, regression, time series)\n",
              "44    i measured one response variable y as a function of two measured independent variables x and x it is common practice in my field of research to transform y into another response variable y x y the...  ...       (logistic, r, regression, time series)\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "execution_count": 126,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K868o9U3H5u0"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG_KIc1xhl2V"
      },
      "outputs": [],
      "source": [
        "def predict_tag(comment):\n",
        "  text=[]\n",
        "\n",
        "  #preprocess\n",
        "  text = [cleaner(comment)]\n",
        "\n",
        "  #convert to integer sequences\n",
        "  seq = x_tokenizer.texts_to_sequences(text)\n",
        "\n",
        "  #pad the sequence\n",
        "  pad_seq = pad_sequences(seq,  padding='post', maxlen=max_len)\n",
        "\n",
        "  #make predictions\n",
        "  pred_prob = model.predict(pad_seq)\n",
        "  classes = classify(pred_prob,opt)[0]\n",
        "\n",
        "  classes = np.array([classes])\n",
        "  classes = mlb.inverse_transform(classes)\n",
        "  return classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "0Al3kfEgEYhU",
        "outputId": "e19f4f50-ef01-4aa3-fb5d-da022911c275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comment: For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\n",
            "Predicted Tags: [('classification', 'logistic', 'machine learning', 'regression')]\n"
          ]
        }
      ],
      "source": [
        "comment = \"For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\"\n",
        "\n",
        "print(\"Comment:\",comment)\n",
        "print(\"Predicted Tags:\",predict_tag(comment))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}